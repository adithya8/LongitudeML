{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LongitudeML Documentation \u00b6 LongitudeML is a machine learning framework for longitudinal forecasting, particularly suited for time-series and sequence prediction tasks in health and behavioral domains. It provides utilities for data loading, preprocessing, model definition (including transformers and recurrent models), and training using PyTorch Lightning. Documentation Structure \u00b6 index.md : Project overview and documentation guide (this file). data_pipeline.md : Data extraction, processing, and preparation pipeline, with detailed method reference for DLATKDataGetter and related utilities. datamodule.md : Dataset preparation, masking, and DataLoader setup, with detailed method reference for all key functions and classes. models.md : Model architectures (recurrent, transformer, linear), including argument tables for forward() methods. lightning_module.md : PyTorch Lightning integration for training and evaluation, with a step-by-step breakdown of the workflow. sklearn_trainer.md : Scikit-learn model integration with PyTorch DataLoaders, including SklearnModule and SklearnTrainer for simple sklearn models. evaluation.md : Evaluation metrics, reduction modes, expected tensor shapes, and usage examples. logger.md : Logging utilities for experiment tracking and hyperparameter logging. mi_args.md : Full argument/configuration reference, with tables for all command-line/configuration options. utils.md : Quick links to evaluation and logger documentation. examples.md : Walkthroughs of example scripts, showing how to use the package end-to-end. Main Components \u00b6 Data Pipeline : Utilities for extracting and processing longitudinal data from databases ( data_pipeline.md ). Data Module : Classes and functions for preparing datasets and dataloaders ( datamodule.md ). Models : Recurrent, transformer, and linear models for sequence prediction ( models.md ). Lightning Module : PyTorch Lightning integration for training and evaluation ( lightning_module.md ). Sklearn Trainer : Scikit-learn model integration with PyTorch DataLoaders for simple models like Ridge and Lasso ( sklearn_trainer.md ). Evaluation : Flexible metrics and reduction modes for grouped/longitudinal data ( evaluation.md ). Logging : Experiment tracking and hyperparameter logging ( logger.md ). Arguments : All configuration options and command-line arguments ( mi_args.md ). Examples : End-to-end workflows and script walkthroughs ( examples.md ). Example Usage \u00b6 See examples.md for walkthroughs of typical workflows using LongitudeML.","title":"Home"},{"location":"#longitudeml-documentation","text":"LongitudeML is a machine learning framework for longitudinal forecasting, particularly suited for time-series and sequence prediction tasks in health and behavioral domains. It provides utilities for data loading, preprocessing, model definition (including transformers and recurrent models), and training using PyTorch Lightning.","title":"LongitudeML Documentation"},{"location":"#documentation-structure","text":"index.md : Project overview and documentation guide (this file). data_pipeline.md : Data extraction, processing, and preparation pipeline, with detailed method reference for DLATKDataGetter and related utilities. datamodule.md : Dataset preparation, masking, and DataLoader setup, with detailed method reference for all key functions and classes. models.md : Model architectures (recurrent, transformer, linear), including argument tables for forward() methods. lightning_module.md : PyTorch Lightning integration for training and evaluation, with a step-by-step breakdown of the workflow. sklearn_trainer.md : Scikit-learn model integration with PyTorch DataLoaders, including SklearnModule and SklearnTrainer for simple sklearn models. evaluation.md : Evaluation metrics, reduction modes, expected tensor shapes, and usage examples. logger.md : Logging utilities for experiment tracking and hyperparameter logging. mi_args.md : Full argument/configuration reference, with tables for all command-line/configuration options. utils.md : Quick links to evaluation and logger documentation. examples.md : Walkthroughs of example scripts, showing how to use the package end-to-end.","title":"Documentation Structure"},{"location":"#main-components","text":"Data Pipeline : Utilities for extracting and processing longitudinal data from databases ( data_pipeline.md ). Data Module : Classes and functions for preparing datasets and dataloaders ( datamodule.md ). Models : Recurrent, transformer, and linear models for sequence prediction ( models.md ). Lightning Module : PyTorch Lightning integration for training and evaluation ( lightning_module.md ). Sklearn Trainer : Scikit-learn model integration with PyTorch DataLoaders for simple models like Ridge and Lasso ( sklearn_trainer.md ). Evaluation : Flexible metrics and reduction modes for grouped/longitudinal data ( evaluation.md ). Logging : Experiment tracking and hyperparameter logging ( logger.md ). Arguments : All configuration options and command-line arguments ( mi_args.md ). Examples : End-to-end workflows and script walkthroughs ( examples.md ).","title":"Main Components"},{"location":"#example-usage","text":"See examples.md for walkthroughs of typical workflows using LongitudeML.","title":"Example Usage"},{"location":"data_pipeline/","text":"Data Pipeline: DLATKDataGetter and Utilities \u00b6 Overview \u00b6 The data pipeline utilities in LongitudeML are designed to extract, process, and prepare longitudinal data from relational databases (e.g., MySQL) for forecasting tasks. The main class is DLATKDataGetter , which interfaces with feature and outcome tables to produce datasets suitable for modeling. DLATKDataGetter: Method Reference \u00b6 get_feature_tables(feature_tables=None, where='') \u00b6 What it does: Retrieves features for each query/message from one or more feature tables, optionally filtered by a SQL where clause. Inputs: - feature_tables (list or str, optional): List of feature table names to use. If not provided, uses the instance\u2019s feature_tables . - where (str, optional): SQL WHERE clause to filter rows. Output: - Tuple: - features_dict : {query_id: [emb1, emb2, ...], ...} (features for each query/message) - features_names : [[feat1, feat2, ...]_table1, [feat1, feat2, ...]_table2, ...] (list of feature names per table) get_long_features(where='', qry_seq_time_id_table=None) \u00b6 What it does: Builds a longitudinal (sequence/time) representation of features, grouped by sequence and ordered by time. Inputs: - where (str, optional): SQL WHERE clause to filter messages. - qry_seq_time_id_table (str, optional): Table to use for mapping query IDs to sequence and time IDs. Defaults to msg_table . Output: - Dict with keys: - 'seq_id' : [sid1, sid2, ...] - 'time_ids' : [[t1, t2, ...]_sid1, [t1, t2, ...]_sid2, ...] - 'embeddings' : [[[emb1, emb2, ...]_t1, ...]_sid1, ...] - 'embeddings_names' : [[feat1, feat2, ...]_table1, ...] get_outcomes(outcome_fields=None, correl_field=None, where='') \u00b6 What it does: Retrieves outcome values for each sequence or query, optionally filtered. Inputs: - outcome_fields (list or str, optional): Outcome field(s) to retrieve. Defaults to instance\u2019s outcome_fields . - correl_field (str, optional): Field to use for correlation (e.g., sequence or query ID). - where (str, optional): SQL WHERE clause. Output: - Dict: {seq_id: [outcome1, outcome2, ...], ...} get_long_outcomes(outcome_fields=None, where='') \u00b6 What it does: Builds a longitudinal (sequence/time) representation of outcomes, grouped by sequence and ordered by time. Inputs: - outcome_fields (list or str, optional): Outcome field(s) to retrieve. - where (str, optional): SQL WHERE clause. Output: - Dict with keys: - 'seq_id' : [sid1, sid2, ...] - 'time_ids' : [[t1, t2, ...]_sid1, ...] - 'outcomes' : [[[outcome1, ...]_t1, ...]_sid1, ...] - 'outcomes_names' : [outcome_name1, ...] intersect_seqids(long_dict1, long_dict2) \u00b6 What it does: Aligns two longitudinal dictionaries (e.g., features and outcomes) to only include common sequence IDs. Inputs: - long_dict1 , long_dict2 : Dicts with 'seq_id' keys. Output: - Tuple: (long_dict1_aligned, long_dict2_aligned) (both only contain common sequence IDs) combine_features_and_outcomes(outcomes_correl_field=None, features_where='', outcomes_where='') \u00b6 What it does: Merges features and outcomes into a single data dictionary suitable for modeling. Inputs: - outcomes_correl_field (str, optional): Field to use for correlating features and outcomes. - features_where , outcomes_where (str, optional): SQL WHERE clauses for filtering. Output: - Dict with keys: - 'seq_idx' : [seq_id1, ...] - 'time_ids' : [[t1, t2, ...], ...] - 'embeddings' : [[[emb1, ...], ...], ...] - 'labels' : [[label1, ...], ...] - 'query_ids' : [[qry_id1, ...], ...] train_test_split(dataset_dict, test_ratio=0.2, val_ratio=0.0, stratify=None) \u00b6 What it does: Splits a dataset dictionary into train, validation, and test sets. Inputs: - dataset_dict (dict): Data dictionary (as output by combine_features_and_outcomes ). - test_ratio (float): Fraction for test set. - val_ratio (float): Fraction for validation set. - stratify (optional): Stratification labels. Output: - Dict: {'train_data': ..., 'val_data': ..., 'test_data': ...} (each is a data dictionary) n_fold_split(dataset_dict, longtype_encoder, fold_column) \u00b6 What it does: Splits the dataset into n folds for cross-validation, based on a fold column. Inputs: - dataset_dict (dict): Data dictionary. - longtype_encoder (dict): Mapping of sequence/query IDs. - fold_column (str): Name of the column in the outcomes table indicating fold assignment. Output: - Dict: Same as input, but with a 'folds' key indicating fold assignment for each sequence. Example Usage \u00b6 from src.dlatk_datapipeline import DLATKDataGetter # Initialize with table names and outcome fields getter = DLATKDataGetter( msg_table='messages', feature_tables=['features_table1', 'features_table2'], outcome_table='outcomes', outcome_fields=['pcl_score'] ) # Get features and outcomes features = getter.get_long_features() outcomes = getter.get_long_outcomes() # Align and merge features, outcomes = getter.intersect_seqids(features, outcomes) dataset = getter.combine_features_and_outcomes() See also: examples/ptsd_stop_forecasting/save_1_day_forecast_data_lang_selfreport_v6.2.py for a full data preparation pipeline.","title":"Data Pipeline"},{"location":"data_pipeline/#data-pipeline-dlatkdatagetter-and-utilities","text":"","title":"Data Pipeline: DLATKDataGetter and Utilities"},{"location":"data_pipeline/#overview","text":"The data pipeline utilities in LongitudeML are designed to extract, process, and prepare longitudinal data from relational databases (e.g., MySQL) for forecasting tasks. The main class is DLATKDataGetter , which interfaces with feature and outcome tables to produce datasets suitable for modeling.","title":"Overview"},{"location":"data_pipeline/#dlatkdatagetter-method-reference","text":"","title":"DLATKDataGetter: Method Reference"},{"location":"data_pipeline/#get_feature_tablesfeature_tablesnone-where","text":"What it does: Retrieves features for each query/message from one or more feature tables, optionally filtered by a SQL where clause. Inputs: - feature_tables (list or str, optional): List of feature table names to use. If not provided, uses the instance\u2019s feature_tables . - where (str, optional): SQL WHERE clause to filter rows. Output: - Tuple: - features_dict : {query_id: [emb1, emb2, ...], ...} (features for each query/message) - features_names : [[feat1, feat2, ...]_table1, [feat1, feat2, ...]_table2, ...] (list of feature names per table)","title":"get_feature_tables(feature_tables=None, where='')"},{"location":"data_pipeline/#get_long_featureswhere-qry_seq_time_id_tablenone","text":"What it does: Builds a longitudinal (sequence/time) representation of features, grouped by sequence and ordered by time. Inputs: - where (str, optional): SQL WHERE clause to filter messages. - qry_seq_time_id_table (str, optional): Table to use for mapping query IDs to sequence and time IDs. Defaults to msg_table . Output: - Dict with keys: - 'seq_id' : [sid1, sid2, ...] - 'time_ids' : [[t1, t2, ...]_sid1, [t1, t2, ...]_sid2, ...] - 'embeddings' : [[[emb1, emb2, ...]_t1, ...]_sid1, ...] - 'embeddings_names' : [[feat1, feat2, ...]_table1, ...]","title":"get_long_features(where='', qry_seq_time_id_table=None)"},{"location":"data_pipeline/#get_outcomesoutcome_fieldsnone-correl_fieldnone-where","text":"What it does: Retrieves outcome values for each sequence or query, optionally filtered. Inputs: - outcome_fields (list or str, optional): Outcome field(s) to retrieve. Defaults to instance\u2019s outcome_fields . - correl_field (str, optional): Field to use for correlation (e.g., sequence or query ID). - where (str, optional): SQL WHERE clause. Output: - Dict: {seq_id: [outcome1, outcome2, ...], ...}","title":"get_outcomes(outcome_fields=None, correl_field=None, where='')"},{"location":"data_pipeline/#get_long_outcomesoutcome_fieldsnone-where","text":"What it does: Builds a longitudinal (sequence/time) representation of outcomes, grouped by sequence and ordered by time. Inputs: - outcome_fields (list or str, optional): Outcome field(s) to retrieve. - where (str, optional): SQL WHERE clause. Output: - Dict with keys: - 'seq_id' : [sid1, sid2, ...] - 'time_ids' : [[t1, t2, ...]_sid1, ...] - 'outcomes' : [[[outcome1, ...]_t1, ...]_sid1, ...] - 'outcomes_names' : [outcome_name1, ...]","title":"get_long_outcomes(outcome_fields=None, where='')"},{"location":"data_pipeline/#intersect_seqidslong_dict1-long_dict2","text":"What it does: Aligns two longitudinal dictionaries (e.g., features and outcomes) to only include common sequence IDs. Inputs: - long_dict1 , long_dict2 : Dicts with 'seq_id' keys. Output: - Tuple: (long_dict1_aligned, long_dict2_aligned) (both only contain common sequence IDs)","title":"intersect_seqids(long_dict1, long_dict2)"},{"location":"data_pipeline/#combine_features_and_outcomesoutcomes_correl_fieldnone-features_where-outcomes_where","text":"What it does: Merges features and outcomes into a single data dictionary suitable for modeling. Inputs: - outcomes_correl_field (str, optional): Field to use for correlating features and outcomes. - features_where , outcomes_where (str, optional): SQL WHERE clauses for filtering. Output: - Dict with keys: - 'seq_idx' : [seq_id1, ...] - 'time_ids' : [[t1, t2, ...], ...] - 'embeddings' : [[[emb1, ...], ...], ...] - 'labels' : [[label1, ...], ...] - 'query_ids' : [[qry_id1, ...], ...]","title":"combine_features_and_outcomes(outcomes_correl_field=None, features_where='', outcomes_where='')"},{"location":"data_pipeline/#train_test_splitdataset_dict-test_ratio02-val_ratio00-stratifynone","text":"What it does: Splits a dataset dictionary into train, validation, and test sets. Inputs: - dataset_dict (dict): Data dictionary (as output by combine_features_and_outcomes ). - test_ratio (float): Fraction for test set. - val_ratio (float): Fraction for validation set. - stratify (optional): Stratification labels. Output: - Dict: {'train_data': ..., 'val_data': ..., 'test_data': ...} (each is a data dictionary)","title":"train_test_split(dataset_dict, test_ratio=0.2, val_ratio=0.0, stratify=None)"},{"location":"data_pipeline/#n_fold_splitdataset_dict-longtype_encoder-fold_column","text":"What it does: Splits the dataset into n folds for cross-validation, based on a fold column. Inputs: - dataset_dict (dict): Data dictionary. - longtype_encoder (dict): Mapping of sequence/query IDs. - fold_column (str): Name of the column in the outcomes table indicating fold assignment. Output: - Dict: Same as input, but with a 'folds' key indicating fold assignment for each sequence.","title":"n_fold_split(dataset_dict, longtype_encoder, fold_column)"},{"location":"data_pipeline/#example-usage","text":"from src.dlatk_datapipeline import DLATKDataGetter # Initialize with table names and outcome fields getter = DLATKDataGetter( msg_table='messages', feature_tables=['features_table1', 'features_table2'], outcome_table='outcomes', outcome_fields=['pcl_score'] ) # Get features and outcomes features = getter.get_long_features() outcomes = getter.get_long_outcomes() # Align and merge features, outcomes = getter.intersect_seqids(features, outcomes) dataset = getter.combine_features_and_outcomes() See also: examples/ptsd_stop_forecasting/save_1_day_forecast_data_lang_selfreport_v6.2.py for a full data preparation pipeline.","title":"Example Usage"},{"location":"datamodule/","text":"Data Module: Dataset Preparation and Loading \u00b6 Overview \u00b6 The data module provides utilities for converting raw data dictionaries into Huggingface Datasets, creating masks for missing data, and preparing PyTorch DataLoaders for model training and evaluation. Method Reference \u00b6 get_dataset(data) \u00b6 What it does: Converts a dictionary of data (with keys like 'embeddings' , 'labels' , etc.) into a Huggingface Dataset object. Automatically creates a 'time_ids' field if not present. Inputs: - data (dict): Dictionary with keys such as 'embeddings' , 'labels' , and optionally 'time_ids' . Output: - Huggingface Dataset object, with all fields as columns. get_datasetDict(train_data, val_data=None, test_data=None, val_folds=None, test_folds=None, fold_col='folds') \u00b6 What it does: Creates a DatasetDict with 'train', 'val', and 'test' splits from input dictionaries or Datasets. Handles fold-based splitting and adds out-of-sample ( ooss_mask ) indicators. Inputs: - train_data , val_data , test_data (dict or Dataset): Data for each split. - val_folds , test_folds (list, optional): Fold indices for validation/test splits. - fold_col (str): Name of the fold column. Output: - Huggingface DatasetDict with keys 'train' , 'val' , 'test' (as available), each a Dataset with added 'ooss_mask' column. OOTS and OOSS OOTS (Out-Of-Time Sample): Refers to data points (usually time points within a user\u2019s sequence) that are held out from the training period and only appear in validation or test sets. This is used to evaluate how well a model generalizes to future/unseen time periods for the same users. OOSS (Out-Of-Sequence Sample): Refers to entire user sequences that are held out from training and only appear in validation or test sets. This is used to evaluate how well a model generalizes to entirely new users (sequences) that were not seen during training. The ooss_mask column in each dataset split indicates whether a sample is an out-of-sequence sample (OOSS), i.e., from a user not present in the training set. If present, an oots_mask column would indicate out-of-time samples (OOTS), i.e., time points that occur after the training period for a given user. create_mask(examples) \u00b6 What it does: Adds mask fields to each sequence for handling missing time points and infilling missing vectors/labels. Used with .map() on a Dataset. Inputs: - examples (dict): A single example or batch from a Dataset, with 'time_ids' , 'embeddings' , 'labels' , etc. Output: - Modified example(s) with added 'mask' and 'infill_mask' fields, indicating valid/missing time points. default_collate_fn(features, predict_last_valid_timestep, partition) \u00b6 What it does: Custom collate function for PyTorch DataLoader, handling padding, masking, and batching of variable-length sequences. Inputs: - features (list of dict): List of examples from the Dataset. - predict_last_valid_timestep (bool): Whether to predict only the last valid timestep. - partition (str): One of 'train' , 'val' , or 'test' . Output: - Batch dictionary with all fields padded and batched appropriately for model input. MIDataLoaderModule(data_args, datasets, partion_processing=True) \u00b6 What it does: A PyTorch Lightning LightningDataModule that wraps the above utilities and provides train_dataloader , val_dataloader , and test_dataloader methods. Inputs: - data_args : Namespace or object with data-related arguments (e.g., batch size, predict_last_valid_timestep). - datasets (dict): Dictionary with keys 'train' , 'val' , 'test' (each a Dataset). - partion_processing (bool): Whether to use partition-specific collate functions. Output: - An object with methods: - train_dataloader() : Returns a DataLoader for training. - val_dataloader() : Returns a DataLoader for validation. - test_dataloader() : Returns a DataLoader for testing. Example Usage \u00b6 from src.mi_datamodule import get_datasetDict, MIDataLoaderModule # Prepare datasets dataset_dict = get_datasetDict(train_data, val_data, test_data) # Create DataLoader module for PyTorch Lightning data_module = MIDataLoaderModule(args, dataset_dict) train_loader = data_module.train_dataloader() val_loader = data_module.val_dataloader() See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for how these are used in practice.","title":"Data Module"},{"location":"datamodule/#data-module-dataset-preparation-and-loading","text":"","title":"Data Module: Dataset Preparation and Loading"},{"location":"datamodule/#overview","text":"The data module provides utilities for converting raw data dictionaries into Huggingface Datasets, creating masks for missing data, and preparing PyTorch DataLoaders for model training and evaluation.","title":"Overview"},{"location":"datamodule/#method-reference","text":"","title":"Method Reference"},{"location":"datamodule/#get_datasetdata","text":"What it does: Converts a dictionary of data (with keys like 'embeddings' , 'labels' , etc.) into a Huggingface Dataset object. Automatically creates a 'time_ids' field if not present. Inputs: - data (dict): Dictionary with keys such as 'embeddings' , 'labels' , and optionally 'time_ids' . Output: - Huggingface Dataset object, with all fields as columns.","title":"get_dataset(data)"},{"location":"datamodule/#get_datasetdicttrain_data-val_datanone-test_datanone-val_foldsnone-test_foldsnone-fold_colfolds","text":"What it does: Creates a DatasetDict with 'train', 'val', and 'test' splits from input dictionaries or Datasets. Handles fold-based splitting and adds out-of-sample ( ooss_mask ) indicators. Inputs: - train_data , val_data , test_data (dict or Dataset): Data for each split. - val_folds , test_folds (list, optional): Fold indices for validation/test splits. - fold_col (str): Name of the fold column. Output: - Huggingface DatasetDict with keys 'train' , 'val' , 'test' (as available), each a Dataset with added 'ooss_mask' column. OOTS and OOSS OOTS (Out-Of-Time Sample): Refers to data points (usually time points within a user\u2019s sequence) that are held out from the training period and only appear in validation or test sets. This is used to evaluate how well a model generalizes to future/unseen time periods for the same users. OOSS (Out-Of-Sequence Sample): Refers to entire user sequences that are held out from training and only appear in validation or test sets. This is used to evaluate how well a model generalizes to entirely new users (sequences) that were not seen during training. The ooss_mask column in each dataset split indicates whether a sample is an out-of-sequence sample (OOSS), i.e., from a user not present in the training set. If present, an oots_mask column would indicate out-of-time samples (OOTS), i.e., time points that occur after the training period for a given user.","title":"get_datasetDict(train_data, val_data=None, test_data=None, val_folds=None, test_folds=None, fold_col='folds')"},{"location":"datamodule/#create_maskexamples","text":"What it does: Adds mask fields to each sequence for handling missing time points and infilling missing vectors/labels. Used with .map() on a Dataset. Inputs: - examples (dict): A single example or batch from a Dataset, with 'time_ids' , 'embeddings' , 'labels' , etc. Output: - Modified example(s) with added 'mask' and 'infill_mask' fields, indicating valid/missing time points.","title":"create_mask(examples)"},{"location":"datamodule/#default_collate_fnfeatures-predict_last_valid_timestep-partition","text":"What it does: Custom collate function for PyTorch DataLoader, handling padding, masking, and batching of variable-length sequences. Inputs: - features (list of dict): List of examples from the Dataset. - predict_last_valid_timestep (bool): Whether to predict only the last valid timestep. - partition (str): One of 'train' , 'val' , or 'test' . Output: - Batch dictionary with all fields padded and batched appropriately for model input.","title":"default_collate_fn(features, predict_last_valid_timestep, partition)"},{"location":"datamodule/#midataloadermoduledata_args-datasets-partion_processingtrue","text":"What it does: A PyTorch Lightning LightningDataModule that wraps the above utilities and provides train_dataloader , val_dataloader , and test_dataloader methods. Inputs: - data_args : Namespace or object with data-related arguments (e.g., batch size, predict_last_valid_timestep). - datasets (dict): Dictionary with keys 'train' , 'val' , 'test' (each a Dataset). - partion_processing (bool): Whether to use partition-specific collate functions. Output: - An object with methods: - train_dataloader() : Returns a DataLoader for training. - val_dataloader() : Returns a DataLoader for validation. - test_dataloader() : Returns a DataLoader for testing.","title":"MIDataLoaderModule(data_args, datasets, partion_processing=True)"},{"location":"datamodule/#example-usage","text":"from src.mi_datamodule import get_datasetDict, MIDataLoaderModule # Prepare datasets dataset_dict = get_datasetDict(train_data, val_data, test_data) # Create DataLoader module for PyTorch Lightning data_module = MIDataLoaderModule(args, dataset_dict) train_loader = data_module.train_dataloader() val_loader = data_module.val_dataloader() See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for how these are used in practice.","title":"Example Usage"},{"location":"evaluation/","text":"Evaluation Metrics \u00b6 LongitudeML provides flexible evaluation metrics for regression and classification tasks, supporting sequence masking and multiple aggregation modes. Metric Functions \u00b6 mi_mse , mi_smape , mi_pearsonr , mi_mae \u00b6 These functions compute mean squared error, symmetric mean absolute percentage error, Pearson correlation, and mean absolute error, respectively. They support sequence masking and different reduction (aggregation) modes. Expected Tensor Shapes \u00b6 input (preds): (batch_size, seq_len, num_outcomes) target : (batch_size, seq_len, num_outcomes) mask : (batch_size, seq_len, num_outcomes) (1=valid, 0=invalid/padded); if not provided, all elements are considered valid Reduction Modes ( reduction argument) \u00b6 The reduction argument controls how metrics are aggregated: Mode Description within-seq Computes the metric within each sequence (e.g., per user or per sample), then averages across all sequences. This is the default and is useful when you want to respect the temporal or grouped structure of your data. between-seq Computes the metric between sequence means : first averages predictions and targets over time within each sequence, then computes the metric on these means across sequences. Use this to evaluate performance at the sequence (e.g., user) level, ignoring within-sequence variation. flatten Flattens all sequences and time steps into a single vector, then computes the metric globally. Use this for a global, ungrouped assessment. none Returns the metric for each element (no reduction). Useful for debugging or custom aggregation. When to use each mode: - Use within-seq for most longitudinal or grouped prediction tasks where you care about per-sequence accuracy. - Use between-seq if your downstream task is to predict sequence-level aggregates (e.g., mean outcome per user). - Use flatten for a global view, ignoring sequence boundaries. - Use none for raw, unreduced metrics. Example Usage \u00b6 from src import mi_mse # Suppose preds, targets, and mask are torch tensors of shape (batch_size, seq_len, num_outcomes) # Example: batch_size=32, seq_len=10, num_outcomes=1 mse_within = mi_mse(input=preds, target=targets, mask=mask) # Default: reduction='within-seq' mse_flatten = mi_mse(input=preds, target=targets, mask=mask, reduction='flatten') mse_between = mi_mse(input=preds, target=targets, mask=mask, reduction='between-seq') See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for more usage examples.","title":"Evaluation"},{"location":"evaluation/#evaluation-metrics","text":"LongitudeML provides flexible evaluation metrics for regression and classification tasks, supporting sequence masking and multiple aggregation modes.","title":"Evaluation Metrics"},{"location":"evaluation/#metric-functions","text":"","title":"Metric Functions"},{"location":"evaluation/#mi_mse-mi_smape-mi_pearsonr-mi_mae","text":"These functions compute mean squared error, symmetric mean absolute percentage error, Pearson correlation, and mean absolute error, respectively. They support sequence masking and different reduction (aggregation) modes.","title":"mi_mse, mi_smape, mi_pearsonr, mi_mae"},{"location":"evaluation/#expected-tensor-shapes","text":"input (preds): (batch_size, seq_len, num_outcomes) target : (batch_size, seq_len, num_outcomes) mask : (batch_size, seq_len, num_outcomes) (1=valid, 0=invalid/padded); if not provided, all elements are considered valid","title":"Expected Tensor Shapes"},{"location":"evaluation/#reduction-modes-reduction-argument","text":"The reduction argument controls how metrics are aggregated: Mode Description within-seq Computes the metric within each sequence (e.g., per user or per sample), then averages across all sequences. This is the default and is useful when you want to respect the temporal or grouped structure of your data. between-seq Computes the metric between sequence means : first averages predictions and targets over time within each sequence, then computes the metric on these means across sequences. Use this to evaluate performance at the sequence (e.g., user) level, ignoring within-sequence variation. flatten Flattens all sequences and time steps into a single vector, then computes the metric globally. Use this for a global, ungrouped assessment. none Returns the metric for each element (no reduction). Useful for debugging or custom aggregation. When to use each mode: - Use within-seq for most longitudinal or grouped prediction tasks where you care about per-sequence accuracy. - Use between-seq if your downstream task is to predict sequence-level aggregates (e.g., mean outcome per user). - Use flatten for a global view, ignoring sequence boundaries. - Use none for raw, unreduced metrics.","title":"Reduction Modes (reduction argument)"},{"location":"evaluation/#example-usage","text":"from src import mi_mse # Suppose preds, targets, and mask are torch tensors of shape (batch_size, seq_len, num_outcomes) # Example: batch_size=32, seq_len=10, num_outcomes=1 mse_within = mi_mse(input=preds, target=targets, mask=mask) # Default: reduction='within-seq' mse_flatten = mi_mse(input=preds, target=targets, mask=mask, reduction='flatten') mse_between = mi_mse(input=preds, target=targets, mask=mask, reduction='between-seq') See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for more usage examples.","title":"Example Usage"},{"location":"examples/","text":"Example Workflows \u00b6 This page demonstrates how to use LongitudeML for longitudinal forecasting tasks, based on the example scripts in examples/ptsd_stop_forecasting/ . 1. Forecasting with PyTorch Lightning ( run_PCL_forecast.py ) \u00b6 This script shows how to set up a full training pipeline using the modules in src/ . Steps: \u00b6 Argument Parsing : Load default arguments for data, model, and training. Data Loading : Use get_datasetDict to prepare train/val/test splits from disk or database. Logger Setup : Initialize experiment logger with get_logger . DataLoader Module : Create a MIDataLoaderModule for PyTorch Lightning. Model Selection : Choose and instantiate a model (recurrent, transformer, or linear) based on arguments. Lightning Module : Wrap the model in MILightningModule for training and evaluation. Training : Use PyTorch Lightning's Trainer to fit the model. Example Code \u00b6 from src import get_default_args, get_logger, get_datasetDict, MIDataLoaderModule, MILightningModule, recurrent, AutoRegressiveTransformer import pytorch_lightning as pl args = get_default_args() datasetDict = get_datasetDict(train_data, val_folds=args.val_folds) logger = get_logger('comet', workspace=args.workspace, project_name=args.project_name, experiment_name=args.experiment_name, save_dir=args.output_dir) data_module = MIDataLoaderModule(args, datasetDict) # Model selection if args.model_type == 'recurrent': model = recurrent(...) elif args.model_type == 'transformer': model = AutoRegressiveTransformer(...) # ... other model options lightning_module = MILightningModule(args, model) trainer = pl.Trainer(max_epochs=args.epochs, logger=logger) trainer.fit(lightning_module, datamodule=data_module) 2. Data Preparation for Forecasting ( save_1_day_forecast_data_lang_selfreport_v6.2.py ) \u00b6 This script demonstrates how to extract, merge, and preprocess longitudinal features and outcomes from a database using the data pipeline utilities. Steps: \u00b6 Initialize DLATKDataGetter : Set up with table names and outcome fields. Extract Features and Outcomes : Use get_long_features and get_long_outcomes . Align and Merge : Use intersect_seqids and merge_features_outcomes to align data by sequence and time. Masking and Normalization : Apply masking and normalization functions to handle missing data and scale features. Save Dataset : Store the processed dataset for downstream modeling. Example Code \u00b6 from src.dlatk_datapipeline import DLATKDataGetter getter = DLATKDataGetter(...) long_embs, long_outcomes = getter.get_long_features(), getter.get_long_outcomes() long_embs, long_outcomes = getter.intersect_seqids(long_embs, long_outcomes) dataset = merge_features_outcomes(long_outcomes, long_embs) # Further processing: masking, normalization, etc. See the full scripts in examples/ptsd_stop_forecasting/ for more details and advanced usage.","title":"Examples"},{"location":"examples/#example-workflows","text":"This page demonstrates how to use LongitudeML for longitudinal forecasting tasks, based on the example scripts in examples/ptsd_stop_forecasting/ .","title":"Example Workflows"},{"location":"examples/#1-forecasting-with-pytorch-lightning-run_pcl_forecastpy","text":"This script shows how to set up a full training pipeline using the modules in src/ .","title":"1. Forecasting with PyTorch Lightning (run_PCL_forecast.py)"},{"location":"examples/#steps","text":"Argument Parsing : Load default arguments for data, model, and training. Data Loading : Use get_datasetDict to prepare train/val/test splits from disk or database. Logger Setup : Initialize experiment logger with get_logger . DataLoader Module : Create a MIDataLoaderModule for PyTorch Lightning. Model Selection : Choose and instantiate a model (recurrent, transformer, or linear) based on arguments. Lightning Module : Wrap the model in MILightningModule for training and evaluation. Training : Use PyTorch Lightning's Trainer to fit the model.","title":"Steps:"},{"location":"examples/#example-code","text":"from src import get_default_args, get_logger, get_datasetDict, MIDataLoaderModule, MILightningModule, recurrent, AutoRegressiveTransformer import pytorch_lightning as pl args = get_default_args() datasetDict = get_datasetDict(train_data, val_folds=args.val_folds) logger = get_logger('comet', workspace=args.workspace, project_name=args.project_name, experiment_name=args.experiment_name, save_dir=args.output_dir) data_module = MIDataLoaderModule(args, datasetDict) # Model selection if args.model_type == 'recurrent': model = recurrent(...) elif args.model_type == 'transformer': model = AutoRegressiveTransformer(...) # ... other model options lightning_module = MILightningModule(args, model) trainer = pl.Trainer(max_epochs=args.epochs, logger=logger) trainer.fit(lightning_module, datamodule=data_module)","title":"Example Code"},{"location":"examples/#2-data-preparation-for-forecasting-save_1_day_forecast_data_lang_selfreport_v62py","text":"This script demonstrates how to extract, merge, and preprocess longitudinal features and outcomes from a database using the data pipeline utilities.","title":"2. Data Preparation for Forecasting (save_1_day_forecast_data_lang_selfreport_v6.2.py)"},{"location":"examples/#steps_1","text":"Initialize DLATKDataGetter : Set up with table names and outcome fields. Extract Features and Outcomes : Use get_long_features and get_long_outcomes . Align and Merge : Use intersect_seqids and merge_features_outcomes to align data by sequence and time. Masking and Normalization : Apply masking and normalization functions to handle missing data and scale features. Save Dataset : Store the processed dataset for downstream modeling.","title":"Steps:"},{"location":"examples/#example-code_1","text":"from src.dlatk_datapipeline import DLATKDataGetter getter = DLATKDataGetter(...) long_embs, long_outcomes = getter.get_long_features(), getter.get_long_outcomes() long_embs, long_outcomes = getter.intersect_seqids(long_embs, long_outcomes) dataset = merge_features_outcomes(long_outcomes, long_embs) # Further processing: masking, normalization, etc. See the full scripts in examples/ptsd_stop_forecasting/ for more details and advanced usage.","title":"Example Code"},{"location":"lightning_module/","text":"Lightning Module: Training and Evaluation \u00b6 Overview \u00b6 MILightningModule is a PyTorch Lightning module that wraps a model and handles training, validation, and testing logic, including loss computation, metrics, and optimizer configuration. Method Reference \u00b6 MILightningModule(args, model) \u00b6 What it does: Wraps a model in a PyTorch Lightning module, handling training, validation, and testing logic, including loss computation, metrics, optimizer configuration, and logging. Inputs: - args : Namespace or object containing all hyperparameters and configuration options (see mi_args.py ). - model : A PyTorch model instance (recurrent, transformer, linear, etc.). Output: - An object with the following key methods (all PyTorch Lightning conventions): - training_step(batch, batch_idx) : Runs a training step, computes loss and metrics, logs results. - validation_step(batch, batch_idx) : Runs a validation step, computes loss and metrics, logs results. - test_step(batch, batch_idx) : Runs a test step, computes loss and metrics, logs results. - configure_optimizers() : Returns optimizer (and optionally scheduler) for training. - predict_step(batch, batch_idx) : (Optional) Runs a prediction step. - on_train_epoch_end , on_validation_epoch_end , on_test_epoch_end : (Optional) Custom logic at the end of each epoch. What it expects as input: - Batches as produced by the DataLoader (see datamodule.md ), with keys like 'embeddings' , 'outcomes' , 'mask' , etc. What the output looks like: - Returns loss and logs metrics for each step/epoch. - Stores predictions, targets, and metrics for later analysis. Step-by-Step Breakdown \u00b6 The MILightningModule follows these main steps during training, validation, and testing: 1. Unpack Batch Inputs \u00b6 What it is: - Extracts model inputs, labels, and sequence IDs from the batch dictionary. Expected Input: - Batch dictionary from the DataLoader, with keys like 'embeddings' , 'outcomes' , 'mask' , 'query_ids' , 'seq_id' , etc. Output: - Model input dictionary, labels tensor, and sequence IDs. 2. Label Processing (Pre-Forward) \u00b6 What it is: - Optionally shifts or interpolates labels for change prediction or time-shifted tasks, preparing them for loss computation. Expected Input: - Labels tensor, batch metadata, and configuration flags (e.g., do_shift , interpolated_output ). Output: - Processed labels tensor (may be differenced or interpolated). 3. Forward Pass \u00b6 What it is: - Passes the input batch through the model to obtain predictions. Expected Input: - Model input dictionary (e.g., 'embeddings' , 'mask' , etc.) Output: - Model output tensor (predictions for each sequence/timestep). 4. Label Processing (Post-Forward) \u00b6 What it is: - Optionally \"reshifts\" or post-processes model outputs to align with the original label space (e.g., undoing differencing or interpolation for evaluation/metrics). Expected Input: - Model output tensor, original labels tensor, mask tensor, and configuration flags. Output: - Adjusted model output tensor, aligned with the original label space. 5. Loss Computation \u00b6 What it is: - Computes the loss between model predictions and (processed) labels, using the specified loss function and reduction mode. Expected Input: - Model output tensor, labels tensor, mask tensor, and loss configuration (e.g., reduction mode). Output: - Scalar loss value (or tensor, if no reduction). 6. Metrics Calculation \u00b6 What it is: - Computes evaluation metrics (e.g., MSE, SMAPE, Pearson, MAE) for the batch, using the specified reduction mode. Expected Input: - Model output tensor, labels tensor, mask tensor, and metrics configuration. Output: - Dictionary of metric values (e.g., {'mse': ..., 'smape': ...} ) 7. Logging and Output Storage \u00b6 What it is: - Logs loss and metrics to the logger, and stores predictions, labels, and metrics for later analysis. Expected Input: - Loss value, metrics dictionary, batch metadata, and logger instance. Output: - None (side effect: logs and stores results internally) 8. Optimizer Step (Training Only) \u00b6 What it is: - Performs an optimizer step to update model parameters (if in training mode). Expected Input: - Computed loss value, optimizer instance. Output: - None (side effect: updates model parameters) Key Features \u00b6 Integrates any LongitudeML model (recurrent, transformer, linear, etc.) Supports custom loss functions and metrics (MSE, SMAPE, Pearson correlation, MAE) Handles sequence masking, out-of-sample indicators, and time-shifted labels Configures optimizers and learning rate schedulers Stores and logs predictions, losses, and metrics for each epoch Example Usage \u00b6 from src import MILightningModule # Assume `args` is a namespace of hyperparameters and `model` is a model instance lightning_module = MILightningModule(args, model) # Use with PyTorch Lightning Trainer import pytorch_lightning as pl trainer = pl.Trainer(max_epochs=args.epochs, logger=logger) trainer.fit(lightning_module, datamodule=data_module) See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for a full training pipeline.","title":"Lightning Module"},{"location":"lightning_module/#lightning-module-training-and-evaluation","text":"","title":"Lightning Module: Training and Evaluation"},{"location":"lightning_module/#overview","text":"MILightningModule is a PyTorch Lightning module that wraps a model and handles training, validation, and testing logic, including loss computation, metrics, and optimizer configuration.","title":"Overview"},{"location":"lightning_module/#method-reference","text":"","title":"Method Reference"},{"location":"lightning_module/#milightningmoduleargs-model","text":"What it does: Wraps a model in a PyTorch Lightning module, handling training, validation, and testing logic, including loss computation, metrics, optimizer configuration, and logging. Inputs: - args : Namespace or object containing all hyperparameters and configuration options (see mi_args.py ). - model : A PyTorch model instance (recurrent, transformer, linear, etc.). Output: - An object with the following key methods (all PyTorch Lightning conventions): - training_step(batch, batch_idx) : Runs a training step, computes loss and metrics, logs results. - validation_step(batch, batch_idx) : Runs a validation step, computes loss and metrics, logs results. - test_step(batch, batch_idx) : Runs a test step, computes loss and metrics, logs results. - configure_optimizers() : Returns optimizer (and optionally scheduler) for training. - predict_step(batch, batch_idx) : (Optional) Runs a prediction step. - on_train_epoch_end , on_validation_epoch_end , on_test_epoch_end : (Optional) Custom logic at the end of each epoch. What it expects as input: - Batches as produced by the DataLoader (see datamodule.md ), with keys like 'embeddings' , 'outcomes' , 'mask' , etc. What the output looks like: - Returns loss and logs metrics for each step/epoch. - Stores predictions, targets, and metrics for later analysis.","title":"MILightningModule(args, model)"},{"location":"lightning_module/#step-by-step-breakdown","text":"The MILightningModule follows these main steps during training, validation, and testing:","title":"Step-by-Step Breakdown"},{"location":"lightning_module/#1-unpack-batch-inputs","text":"What it is: - Extracts model inputs, labels, and sequence IDs from the batch dictionary. Expected Input: - Batch dictionary from the DataLoader, with keys like 'embeddings' , 'outcomes' , 'mask' , 'query_ids' , 'seq_id' , etc. Output: - Model input dictionary, labels tensor, and sequence IDs.","title":"1. Unpack Batch Inputs"},{"location":"lightning_module/#2-label-processing-pre-forward","text":"What it is: - Optionally shifts or interpolates labels for change prediction or time-shifted tasks, preparing them for loss computation. Expected Input: - Labels tensor, batch metadata, and configuration flags (e.g., do_shift , interpolated_output ). Output: - Processed labels tensor (may be differenced or interpolated).","title":"2. Label Processing (Pre-Forward)"},{"location":"lightning_module/#3-forward-pass","text":"What it is: - Passes the input batch through the model to obtain predictions. Expected Input: - Model input dictionary (e.g., 'embeddings' , 'mask' , etc.) Output: - Model output tensor (predictions for each sequence/timestep).","title":"3. Forward Pass"},{"location":"lightning_module/#4-label-processing-post-forward","text":"What it is: - Optionally \"reshifts\" or post-processes model outputs to align with the original label space (e.g., undoing differencing or interpolation for evaluation/metrics). Expected Input: - Model output tensor, original labels tensor, mask tensor, and configuration flags. Output: - Adjusted model output tensor, aligned with the original label space.","title":"4. Label Processing (Post-Forward)"},{"location":"lightning_module/#5-loss-computation","text":"What it is: - Computes the loss between model predictions and (processed) labels, using the specified loss function and reduction mode. Expected Input: - Model output tensor, labels tensor, mask tensor, and loss configuration (e.g., reduction mode). Output: - Scalar loss value (or tensor, if no reduction).","title":"5. Loss Computation"},{"location":"lightning_module/#6-metrics-calculation","text":"What it is: - Computes evaluation metrics (e.g., MSE, SMAPE, Pearson, MAE) for the batch, using the specified reduction mode. Expected Input: - Model output tensor, labels tensor, mask tensor, and metrics configuration. Output: - Dictionary of metric values (e.g., {'mse': ..., 'smape': ...} )","title":"6. Metrics Calculation"},{"location":"lightning_module/#7-logging-and-output-storage","text":"What it is: - Logs loss and metrics to the logger, and stores predictions, labels, and metrics for later analysis. Expected Input: - Loss value, metrics dictionary, batch metadata, and logger instance. Output: - None (side effect: logs and stores results internally)","title":"7. Logging and Output Storage"},{"location":"lightning_module/#8-optimizer-step-training-only","text":"What it is: - Performs an optimizer step to update model parameters (if in training mode). Expected Input: - Computed loss value, optimizer instance. Output: - None (side effect: updates model parameters)","title":"8. Optimizer Step (Training Only)"},{"location":"lightning_module/#key-features","text":"Integrates any LongitudeML model (recurrent, transformer, linear, etc.) Supports custom loss functions and metrics (MSE, SMAPE, Pearson correlation, MAE) Handles sequence masking, out-of-sample indicators, and time-shifted labels Configures optimizers and learning rate schedulers Stores and logs predictions, losses, and metrics for each epoch","title":"Key Features"},{"location":"lightning_module/#example-usage","text":"from src import MILightningModule # Assume `args` is a namespace of hyperparameters and `model` is a model instance lightning_module = MILightningModule(args, model) # Use with PyTorch Lightning Trainer import pytorch_lightning as pl trainer = pl.Trainer(max_epochs=args.epochs, logger=logger) trainer.fit(lightning_module, datamodule=data_module) See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for a full training pipeline.","title":"Example Usage"},{"location":"logger/","text":"Logging Utilities \u00b6 LongitudeML provides logging utilities for experiment tracking, hyperparameter logging, and result saving, with support for CometML and other backends. Logger Function \u00b6 get_logger \u00b6 Initializes a logger for experiment tracking. Supports logging hyperparameters, metrics, and saving results to disk or remote services (e.g., CometML). Example Usage \u00b6 from src import get_logger logger = get_logger('comet', workspace='my_workspace', project_name='my_project', experiment_name='exp1', save_dir='./logs') logger.log_hyperparams(args.__dict__) workspace , project_name , experiment_name , and save_dir are typical arguments for configuring the logger. The logger can be passed to PyTorch Lightning's Trainer for integrated experiment tracking. See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for logger usage in a full training pipeline.","title":"Logger"},{"location":"logger/#logging-utilities","text":"LongitudeML provides logging utilities for experiment tracking, hyperparameter logging, and result saving, with support for CometML and other backends.","title":"Logging Utilities"},{"location":"logger/#logger-function","text":"","title":"Logger Function"},{"location":"logger/#get_logger","text":"Initializes a logger for experiment tracking. Supports logging hyperparameters, metrics, and saving results to disk or remote services (e.g., CometML).","title":"get_logger"},{"location":"logger/#example-usage","text":"from src import get_logger logger = get_logger('comet', workspace='my_workspace', project_name='my_project', experiment_name='exp1', save_dir='./logs') logger.log_hyperparams(args.__dict__) workspace , project_name , experiment_name , and save_dir are typical arguments for configuring the logger. The logger can be passed to PyTorch Lightning's Trainer for integrated experiment tracking. See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for logger usage in a full training pipeline.","title":"Example Usage"},{"location":"mi_args/","text":"Argument Configuration: mi_args.py \u00b6 Overview \u00b6 The mi_args.py module provides functions to add and parse all command-line arguments and configuration options for data, model, training, and logging. These are typically used to build an argparse.ArgumentParser and produce a Namespace object for use throughout the pipeline. Key Functions and Arguments \u00b6 get_data_args(parser) \u00b6 Adds arguments related to data input/output (e.g., data directory, file paths, output directory) to the parser. Argument Type Default Description --data_dir str None Path to data directory --data_file str None Path to data file --train_file str None Path to training data file --val_file str None Path to validation data file --test_file str None Path to test data file --output_dir str None Output directory --overwrite_output_dir flag False Overwrite output directory get_model_args(parser) \u00b6 Adds arguments related to model architecture and hyperparameters. Argument Type Default Description --model_type str 'gru' Model type (gru, trns, custom, baseline, custom_scratch) --custom_model str None Custom model name --input_size int 768 Size of the embeddings --num_classes int 1 Number of classes --num_outcomes int 1 Number of outcomes --hidden_size int 128 Hidden size --projection_size int None Projection size (default: None, same as hidden_size) --num_layers int 1 Number of layers --dropout float 0.10 Dropout rate --output_dropout float 0.10 Output layer dropout --positional_encoding_type str 'none' Positional encoding type (none, sinusoidal, learned, rope) --pre_ln flag False Use pre-layer normalization --bidirectional flag False Use bidirectional RNN --num_heads int 2 Number of heads for transformer model --max_len int 130 Maximum sequence length for transformer model --max_history_len int None Maximum history length for transformer model --sliding_window_size int None Sliding window size for recalibration get_training_args(parser) \u00b6 Adds arguments related to training, loss/metric reduction, early stopping, and more. Argument Type Default Description --do_train flag False Run training --do_test flag False Run testing --val_folds list [] Folds to validate on --do_hparam_tune flag False Run hyperparameter tuning --n_trials int 100 Number of trials for tuning --min_epochs int 1 Minimum number of epochs --epochs int None Number of epochs to train --train_batch_size int 32 Batch size for training --val_batch_size int 64 Batch size for evaluation --cross_entropy_class_weight list None Class weights for cross entropy loss --loss_reduction str 'flatten' Loss reduction strategy (within-seq, flatten, none) --metrics_reduction str 'within-seq' Metrics reduction strategy (within-seq, between-seq, flatten, none) --do_shift flag False Predict change instead of absolute value --interpolated_output flag False Output is linearly interpolated --seq_len_scheduler_type str 'none' Sequence length scheduler type (none, linear, exponential) --min_seq_len int 10 Minimum sequence length for training --max_seq_len int -1 Maximum sequence length for training --max_scheduled_epochs int -1 Max epochs for sequence length scheduler --log_interval int 10 Logging interval --save_strategy str 'best' Model save strategy (best, all) --save_dir str None Model save directory --lr float 0.001 Learning rate --weight_decay float 0.0 Weight decay --lr_scheduler str 'none' Learning rate scheduler (none, linear) --warmup_epochs int 1 Number of warmup epochs for scheduler --start_factor float 0.5 Start factor for scheduler --num_workers int 4 Number of workers --seed int 42 Random seed --predict_last_valid_timestep flag False Predict from last valid timestep only --early_stopping_patience int 0 Patience for early stopping --early_stopping_min_delta float 0.0 Min delta for early stopping --early_stopping_mode str 'min' Early stopping mode (min, max) --subscale_weights_path str None Path to subscale model weights --lang_weights_path str None Path to language model weights get_comet_args(parser) \u00b6 Adds arguments for CometML experiment tracking. Argument Type Default Description --api_key str ~/.comet.key CometML API key --workspace str None CometML workspace --project_name str None CometML project name --experiment_name str None CometML experiment name get_default_args(jupyter=False) \u00b6 Returns a Namespace object with all default arguments for data, model, training, and logging, ready to use in scripts. Inputs: - jupyter (bool): If True, adds Jupyter-specific arguments for notebook compatibility. Output: - argparse.Namespace object with all arguments and their default values. Example Usage \u00b6 from src.mi_args import get_default_args args = get_default_args() print(args.data_dir, args.model_type, args.epochs, args.workspace, ...)","title":"Arguments"},{"location":"mi_args/#argument-configuration-mi_argspy","text":"","title":"Argument Configuration: mi_args.py"},{"location":"mi_args/#overview","text":"The mi_args.py module provides functions to add and parse all command-line arguments and configuration options for data, model, training, and logging. These are typically used to build an argparse.ArgumentParser and produce a Namespace object for use throughout the pipeline.","title":"Overview"},{"location":"mi_args/#key-functions-and-arguments","text":"","title":"Key Functions and Arguments"},{"location":"mi_args/#get_data_argsparser","text":"Adds arguments related to data input/output (e.g., data directory, file paths, output directory) to the parser. Argument Type Default Description --data_dir str None Path to data directory --data_file str None Path to data file --train_file str None Path to training data file --val_file str None Path to validation data file --test_file str None Path to test data file --output_dir str None Output directory --overwrite_output_dir flag False Overwrite output directory","title":"get_data_args(parser)"},{"location":"mi_args/#get_model_argsparser","text":"Adds arguments related to model architecture and hyperparameters. Argument Type Default Description --model_type str 'gru' Model type (gru, trns, custom, baseline, custom_scratch) --custom_model str None Custom model name --input_size int 768 Size of the embeddings --num_classes int 1 Number of classes --num_outcomes int 1 Number of outcomes --hidden_size int 128 Hidden size --projection_size int None Projection size (default: None, same as hidden_size) --num_layers int 1 Number of layers --dropout float 0.10 Dropout rate --output_dropout float 0.10 Output layer dropout --positional_encoding_type str 'none' Positional encoding type (none, sinusoidal, learned, rope) --pre_ln flag False Use pre-layer normalization --bidirectional flag False Use bidirectional RNN --num_heads int 2 Number of heads for transformer model --max_len int 130 Maximum sequence length for transformer model --max_history_len int None Maximum history length for transformer model --sliding_window_size int None Sliding window size for recalibration","title":"get_model_args(parser)"},{"location":"mi_args/#get_training_argsparser","text":"Adds arguments related to training, loss/metric reduction, early stopping, and more. Argument Type Default Description --do_train flag False Run training --do_test flag False Run testing --val_folds list [] Folds to validate on --do_hparam_tune flag False Run hyperparameter tuning --n_trials int 100 Number of trials for tuning --min_epochs int 1 Minimum number of epochs --epochs int None Number of epochs to train --train_batch_size int 32 Batch size for training --val_batch_size int 64 Batch size for evaluation --cross_entropy_class_weight list None Class weights for cross entropy loss --loss_reduction str 'flatten' Loss reduction strategy (within-seq, flatten, none) --metrics_reduction str 'within-seq' Metrics reduction strategy (within-seq, between-seq, flatten, none) --do_shift flag False Predict change instead of absolute value --interpolated_output flag False Output is linearly interpolated --seq_len_scheduler_type str 'none' Sequence length scheduler type (none, linear, exponential) --min_seq_len int 10 Minimum sequence length for training --max_seq_len int -1 Maximum sequence length for training --max_scheduled_epochs int -1 Max epochs for sequence length scheduler --log_interval int 10 Logging interval --save_strategy str 'best' Model save strategy (best, all) --save_dir str None Model save directory --lr float 0.001 Learning rate --weight_decay float 0.0 Weight decay --lr_scheduler str 'none' Learning rate scheduler (none, linear) --warmup_epochs int 1 Number of warmup epochs for scheduler --start_factor float 0.5 Start factor for scheduler --num_workers int 4 Number of workers --seed int 42 Random seed --predict_last_valid_timestep flag False Predict from last valid timestep only --early_stopping_patience int 0 Patience for early stopping --early_stopping_min_delta float 0.0 Min delta for early stopping --early_stopping_mode str 'min' Early stopping mode (min, max) --subscale_weights_path str None Path to subscale model weights --lang_weights_path str None Path to language model weights","title":"get_training_args(parser)"},{"location":"mi_args/#get_comet_argsparser","text":"Adds arguments for CometML experiment tracking. Argument Type Default Description --api_key str ~/.comet.key CometML API key --workspace str None CometML workspace --project_name str None CometML project name --experiment_name str None CometML experiment name","title":"get_comet_args(parser)"},{"location":"mi_args/#get_default_argsjupyterfalse","text":"Returns a Namespace object with all default arguments for data, model, training, and logging, ready to use in scripts. Inputs: - jupyter (bool): If True, adds Jupyter-specific arguments for notebook compatibility. Output: - argparse.Namespace object with all arguments and their default values.","title":"get_default_args(jupyter=False)"},{"location":"mi_args/#example-usage","text":"from src.mi_args import get_default_args args = get_default_args() print(args.data_dir, args.model_type, args.epochs, args.workspace, ...)","title":"Example Usage"},{"location":"models/","text":"Models: Recurrent, Transformer, and Linear Architectures \u00b6 Overview \u00b6 LongitudeML provides a variety of model architectures for sequence and time-series forecasting, including recurrent neural networks (GRU), transformer-based models, and linear baselines. These are implemented in mi_model.py and mi_transformers.py . Key Model Classes \u00b6 recurrent \u00b6 A GRU-based recurrent model for sequence prediction, supporting multi-instance learning and masking for variable-length sequences. forward() Arguments \u00b6 Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) hidden_rep torch.Tensor No Initial hidden state (num_layers * num_directions, batch_size, hidden_size) mask torch.Tensor No Boolean mask (batch_size, seq_len); 1=valid, 0=invalid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs dict No Additional arguments (not typically used) AutoRegressiveTransformer \u00b6 A transformer model for autoregressive sequence modeling, with support for custom positional encodings and multi-head attention. forward() Arguments \u00b6 Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) mask torch.Tensor No Boolean mask (batch_size, seq_len); 1=padded, 0=valid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs (e.g., time_ids ) dict No Additional arguments, e.g., time_ids for masking TransformerModel \u00b6 A flexible transformer implementation supporting sinusoidal, rotary, or no positional encoding, and configurable for different input/output dimensions. forward() Arguments \u00b6 Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_dim) mask torch.Tensor No Attention mask (batch_size, 1, seq_len, seq_len); -inf for masked, 0 for unmasked **kwargs (e.g., time_ids ) dict No Additional arguments, e.g., time_ids for masking AutoRegressiveLinear \u00b6 Linear model using causal convolution for sequence prediction. forward() Arguments \u00b6 Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) mask torch.Tensor Yes Boolean mask (batch_size, seq_len); 1=padded, 0=valid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs dict No Additional arguments AutoRegressiveLinear2 \u00b6 Linear model using sliding window for autoregressive prediction. forward() Arguments \u00b6 Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) mask torch.Tensor No Boolean mask (batch_size, seq_len); 1=padded, 0=valid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs dict No Additional arguments BoELinear \u00b6 Bag-of-Embeddings linear model, averages embeddings before linear projection. forward() Arguments \u00b6 Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) mask torch.Tensor No Boolean mask (batch_size, seq_len); 1=padded, 0=valid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs dict No Additional arguments Example Usage \u00b6 from src import recurrent, AutoRegressiveTransformer, TransformerModel # Recurrent model model = recurrent(input_size=128, hidden_size=64, num_classes=1, num_layers=2) output = model(embeddings, mask=mask) # Transformer model tr_model = AutoRegressiveTransformer( input_size=128, hidden_size=64, num_classes=1, num_layers=2, num_heads=4, max_len=100 ) output = tr_model(embeddings, mask=mask, time_ids=time_ids) # Linear baseline from src import AutoRegressiveLinear lin_model = AutoRegressiveLinear(input_size=128, hidden_size=64, num_classes=1) output = lin_model(embeddings, mask=mask) See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for model instantiation and selection logic.","title":"Models"},{"location":"models/#models-recurrent-transformer-and-linear-architectures","text":"","title":"Models: Recurrent, Transformer, and Linear Architectures"},{"location":"models/#overview","text":"LongitudeML provides a variety of model architectures for sequence and time-series forecasting, including recurrent neural networks (GRU), transformer-based models, and linear baselines. These are implemented in mi_model.py and mi_transformers.py .","title":"Overview"},{"location":"models/#key-model-classes","text":"","title":"Key Model Classes"},{"location":"models/#recurrent","text":"A GRU-based recurrent model for sequence prediction, supporting multi-instance learning and masking for variable-length sequences.","title":"recurrent"},{"location":"models/#forward-arguments","text":"Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) hidden_rep torch.Tensor No Initial hidden state (num_layers * num_directions, batch_size, hidden_size) mask torch.Tensor No Boolean mask (batch_size, seq_len); 1=valid, 0=invalid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs dict No Additional arguments (not typically used)","title":"forward() Arguments"},{"location":"models/#autoregressivetransformer","text":"A transformer model for autoregressive sequence modeling, with support for custom positional encodings and multi-head attention.","title":"AutoRegressiveTransformer"},{"location":"models/#forward-arguments_1","text":"Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) mask torch.Tensor No Boolean mask (batch_size, seq_len); 1=padded, 0=valid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs (e.g., time_ids ) dict No Additional arguments, e.g., time_ids for masking","title":"forward() Arguments"},{"location":"models/#transformermodel","text":"A flexible transformer implementation supporting sinusoidal, rotary, or no positional encoding, and configurable for different input/output dimensions.","title":"TransformerModel"},{"location":"models/#forward-arguments_2","text":"Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_dim) mask torch.Tensor No Attention mask (batch_size, 1, seq_len, seq_len); -inf for masked, 0 for unmasked **kwargs (e.g., time_ids ) dict No Additional arguments, e.g., time_ids for masking","title":"forward() Arguments"},{"location":"models/#autoregressivelinear","text":"Linear model using causal convolution for sequence prediction.","title":"AutoRegressiveLinear"},{"location":"models/#forward-arguments_3","text":"Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) mask torch.Tensor Yes Boolean mask (batch_size, seq_len); 1=padded, 0=valid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs dict No Additional arguments","title":"forward() Arguments"},{"location":"models/#autoregressivelinear2","text":"Linear model using sliding window for autoregressive prediction.","title":"AutoRegressiveLinear2"},{"location":"models/#forward-arguments_4","text":"Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) mask torch.Tensor No Boolean mask (batch_size, seq_len); 1=padded, 0=valid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs dict No Additional arguments","title":"forward() Arguments"},{"location":"models/#boelinear","text":"Bag-of-Embeddings linear model, averages embeddings before linear projection.","title":"BoELinear"},{"location":"models/#forward-arguments_5","text":"Argument Type Required Description embeddings torch.Tensor Yes Input tensor of shape (batch_size, seq_len, input_size) mask torch.Tensor No Boolean mask (batch_size, seq_len); 1=padded, 0=valid predict_last_valid_hidden_state bool No If True, predict only for last valid timestep; else predict for all timesteps (default=True) **kwargs dict No Additional arguments","title":"forward() Arguments"},{"location":"models/#example-usage","text":"from src import recurrent, AutoRegressiveTransformer, TransformerModel # Recurrent model model = recurrent(input_size=128, hidden_size=64, num_classes=1, num_layers=2) output = model(embeddings, mask=mask) # Transformer model tr_model = AutoRegressiveTransformer( input_size=128, hidden_size=64, num_classes=1, num_layers=2, num_heads=4, max_len=100 ) output = tr_model(embeddings, mask=mask, time_ids=time_ids) # Linear baseline from src import AutoRegressiveLinear lin_model = AutoRegressiveLinear(input_size=128, hidden_size=64, num_classes=1) output = lin_model(embeddings, mask=mask) See also: examples/ptsd_stop_forecasting/run_PCL_forecast.py for model instantiation and selection logic.","title":"Example Usage"},{"location":"sklearn_trainer/","text":"Sklearn Trainer: Scikit-Learn Integration \u00b6 Overview \u00b6 SklearnModule and SklearnTrainer provide a PyTorch Lightning-like interface for scikit-learn models, allowing simple sklearn models (Ridge, Lasso, etc.) to work seamlessly with PyTorch DataLoaders. This is designed for models that have fit() and predict() methods and don't require gradient-based optimization. The sklearn trainer handles the conversion between PyTorch's 3D tensor format (batch_size, seq_len, features) and sklearn's 2D array format (n_samples, n_features), computes comprehensive evaluation metrics across multiple data subsets (OOTS/OOSS), and supports hyperparameter search via GridSearchCV and RandomizedSearchCV. Key Design Pattern : Sklearn models must implement a select_features() method (adapter pattern) that decides which embeddings to use from the batch dictionary, mirroring how PyTorch models choose their inputs. Module Organization : - sklearn_trainer.py : Contains SklearnModule and SklearnTrainer classes for training orchestration - mi_sklearn_model.py : Contains sklearn model adapter classes ( RidgeForecastModel , LassoForecastModel , AutoRegressiveRidge , AutoRegressiveLasso , etc.) Helper Functions \u00b6 collect_batch_dict(dataloader) \u00b6 What it does: Aggregates all batches from a PyTorch DataLoader into a single batch dictionary by concatenating tensors along the batch dimension. Inputs: - dataloader : PyTorch DataLoader yielding dictionary batches with keys like 'embeddings_*' , 'outcomes' , 'outcomes_mask' , 'oots_mask' , 'ooss_mask' , 'time_ids' , 'seq_id' , etc. Output: - Dict[str, torch.Tensor] : Dictionary with the same keys as individual batches, where values are concatenated tensors over all batches along dim=0. reshape_for_sklearn(X, y, mask) \u00b6 What it does: Converts 3D PyTorch tensors to 2D numpy arrays suitable for sklearn models, filtering out invalid samples (where mask is False). Inputs: - X : (batch_size, seq_len, input_dim) tensor - y : (batch_size, seq_len, num_outcomes) tensor - mask : (batch_size, seq_len, num_outcomes) boolean tensor Output: - X_2d : (n_valid_samples, input_dim) numpy array - y_2d : (n_valid_samples, num_outcomes) numpy array - valid_indices : List of (batch_idx, time_idx) tuples for reconstruction Important Note on Multi-Outcome Models: This function uses mask.any(dim=-1) which includes timesteps where at least one outcome is valid. For multi-outcome models, this means: - If outcomes_mask = [1, 1, 0] , this sample is included in training - Sklearn will train on all outcomes, including the invalid one (with mask=0) - This is suboptimal for multi-outcome sklearn models as sklearn wastes effort predicting invalid outcomes For single-outcome models : This is not an issue since there's only one outcome. For multi-outcome models : Consider using separate sklearn models per outcome or modifying this function to use mask.all(dim=-1) to only include fully valid samples. reconstruct_from_sklearn(predictions, original_shape, valid_indices, mask) \u00b6 What it does: Reconstructs 3D predictions from sklearn's 2D output, placing predictions at valid positions and filling invalid positions with zeros. Inputs: - predictions : (n_valid_samples, num_outcomes) numpy array - original_shape : (batch_size, seq_len, num_outcomes) tuple - valid_indices : List of (batch_idx, time_idx) tuples - mask : Original mask tensor (batch_size, seq_len, num_outcomes) Output: - preds_3d : (batch_size, seq_len, num_outcomes) tensor Method Reference \u00b6 SklearnModule(args, model) \u00b6 What it does: Wraps a sklearn model to work with PyTorch DataLoaders, handling data reshaping, training, evaluation, and metric computation. Inputs: - args : Namespace or dict containing hyperparameters and configuration (must include metrics_reduction for metric computation). - model : Sklearn model instance with fit() and predict() methods. Must also implement select_features(batch_dict, args) that returns (X_3d, y_3d, mask_3d) tensors. Output: - An object with the following key methods: - fit(dataloader) : Train the sklearn model and compute training metrics - evaluate(dataloader, split='val') : Evaluate and compute exhaustive metrics for OOTS/OOSS subsets - predict(dataloader) : Make predictions without computing metrics (no labels needed) - compute_metrics(preds, targets, mask) : Compute basic metrics (MSE, SMAPE, Pearson, MAE) - compute_exhaustive_metrics(preds, targets, mask, oots_mask, ooss_mask) : Compute metrics for multiple subsets What it expects as input: - DataLoaders producing batch dictionaries with keys like 'embeddings_*' , 'outcomes' , 'outcomes_mask' , 'oots_mask' , 'ooss_mask' , etc. (see datamodule.md ) What the output looks like: - Stores predictions and metrics internally in self.predictions and self.metrics dictionaries - Returns metric dictionaries from fit() and evaluate() methods fit(dataloader) \u00b6 What it does: Trains the sklearn model on data from the dataloader, computes training metrics, and stores predictions. Inputs: - dataloader : PyTorch DataLoader Output: - Dictionary with training metrics: {'mse': ..., 'smape': ..., 'pearsonr': ..., 'mae': ...} evaluate(dataloader, split='val') \u00b6 What it does: Evaluates the sklearn model and computes metrics for multiple data subsets based on oots_mask and ooss_mask : - ws_wt : within sample, within time (ooss==0 & oots==0) - valset : all validation data (oots==1 OR ooss==1) - ws_oots : within sample, out of time (ooss==0 & oots==1) - wt_ooss : within time, out of sample (ooss==1 & oots==0) - oots_ooss : out of time, out of sample (ooss==1 & oots==1) - oots : all out of time samples (oots==1) - ooss : all out of sample sequences (ooss==1) Inputs: - dataloader : PyTorch DataLoader - split : 'val' or 'test' (used for storing predictions/metrics) Output: - Dictionary with evaluation metrics for all subsets: {'ws_wt_mse': ..., 'valset_mse': ..., 'ws_oots_mse': ..., ...} . Empty subsets return -1.0 for all metrics. predict(dataloader) \u00b6 What it does: Makes predictions without computing metrics (labels are optional). Inputs: - dataloader : PyTorch DataLoader (may not have labels) Output: - Dictionary with keys: 'preds' , 'outcomes' , 'outcomes_mask' , 'seq_id' , 'time_ids' , 'oots_mask' , 'ooss_mask' compute_metrics(preds, targets, mask) \u00b6 What it does: Computes evaluation metrics using mi_eval functions (MSE, SMAPE, Pearson correlation, MAE) with the reduction mode specified in args.metrics_reduction . Inputs: - preds : (batch_size, seq_len, num_outcomes) tensor - targets : (batch_size, seq_len, num_outcomes) tensor - mask : (batch_size, seq_len, num_outcomes) tensor Output: - Dictionary with metric values: {'mse': ..., 'smape': ..., 'pearsonr': ..., 'mae': ...} See evaluation.md for details on reduction modes. compute_exhaustive_metrics(preds, targets, mask, oots_mask, ooss_mask) \u00b6 What it does: Computes metrics for multiple data subsets based on oots_mask and ooss_mask , matching the behavior of MILightningModule.validation_step . Handles shape validation and correctly interprets time-wise oots_mask and sequence-wise ooss_mask . Inputs: - preds : (batch_size, seq_len, num_outcomes) tensor - targets : (batch_size, seq_len, num_outcomes) tensor - mask : (batch_size, seq_len, num_outcomes) tensor - oots_mask : (batch_size, seq_len) tensor - out of time indicator (time-wise) - ooss_mask : (batch_size,) or (batch_size, 1) tensor - out of sample indicator (sequence-wise) Output: - Dictionary with metrics for all subsets (same as evaluate() output) SklearnTrainer(output_dir, logger=None, **trainer_params) \u00b6 What it does: Orchestrates training, validation, testing, and hyperparameter search for sklearn models, similar to PyTorch Lightning's Trainer. Inputs: - output_dir : Directory path for saving models and results - logger : Optional logger instance (Comet, TensorBoard, etc.) for experiment tracking - **trainer_params : Additional trainer configuration parameters Output: - An object with the following key methods: - fit(module, train_dataloader, val_dataloader=None) : Train and optionally validate - validate(module, val_dataloader) : Validate the model - test(module, test_dataloader) : Test the model - predict(module, predict_dataloader) : Make predictions - hyperparameter_search(...) : Perform GridSearchCV or RandomizedSearchCV - save_model(module, filename) : Save module to disk - load_model(filename) : Load saved module from disk fit(module, train_dataloader, val_dataloader=None) \u00b6 What it does: Trains the sklearn model and optionally validates it, logging metrics and saving the model. Inputs: - module : SklearnModule instance - train_dataloader : Training data loader - val_dataloader : Optional validation data loader Output: - Dictionary with keys 'train' and 'val' , each containing metric dictionaries validate(module, val_dataloader) \u00b6 What it does: Validates the model (can be called anytime, not just after training). Inputs: - module : SklearnModule instance - val_dataloader : Validation data loader Output: - Dictionary with validation metrics (exhaustive subset metrics) test(module, test_dataloader) \u00b6 What it does: Tests the model on the test set. Inputs: - module : SklearnModule instance - test_dataloader : Test data loader Output: - Dictionary with test metrics (exhaustive subset metrics) predict(module, predict_dataloader) \u00b6 What it does: Makes predictions without labels. Inputs: - module : SklearnModule instance - predict_dataloader : Data loader (may not have labels) Output: - Dictionary with predictions and metadata hyperparameter_search(module, param_grid, train_dataloader, val_dataloader, search_type='grid', n_iter=10, cv=3) \u00b6 What it does: Performs hyperparameter search using GridSearchCV or RandomizedSearchCV , evaluates the best model on the validation set, and saves it. Inputs: - module : SklearnModule instance (will be cloned internally) - param_grid : Dictionary of parameter names to lists of values (e.g., {'alpha': [0.1, 1.0, 10.0]} ) - train_dataloader : Training data loader - val_dataloader : Validation data loader - search_type : 'grid' or 'random' - n_iter : Number of iterations for random search - cv : Number of cross-validation folds Output: - SklearnModule instance with the best model (from search.best_estimator_ ) save_model(module, filename) \u00b6 What it does: Saves the module (including the sklearn model, args, metrics, and predictions) to disk. Uses output_dir/project_name/experiment_key/ structure when logger is available, otherwise saves to output_dir/ . Inputs: - module : SklearnModule instance - filename : Name of the file to save (e.g., 'final_model.pkl' ) Output: - None (side effect: saves to disk) load_model(filename) \u00b6 What it does: Loads a saved module from disk, reconstructing the SklearnModule with the saved model, args, metrics, and predictions. Inputs: - filename : Name of the file to load Output: - SklearnModule instance Available Sklearn Model Classes \u00b6 Pre-built sklearn model adapters are available in mi_sklearn_model.py : Basic Models (No History Windowing) \u00b6 RidgeForecastModel : Ridge regression adapter that selects embeddings from batch dictionary LassoForecastModel : Lasso regression adapter with the same feature selection logic Autoregressive Models (With History Windowing) \u00b6 AutoRegressiveRidge : Ridge regression with sliding window history (uses args.max_len ) AutoRegressiveLasso : Lasso regression with sliding window history (uses args.max_len ) These models automatically handle history windowing when args.max_len > 1 , expanding each timestep's features to include the current and previous max_len - 1 timesteps. Adapter Pattern: select_features Interface \u00b6 Sklearn models used with SklearnModule must implement a select_features() method that defines how to extract input features, targets, and masks from the aggregated batch dictionary. This mirrors the PyTorch design where the model decides which embeddings_* keys to use. Interface Signature \u00b6 def select_features(self, batch_dict: Dict[str, torch.Tensor], args) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: \"\"\" Args: batch_dict: Dictionary with keys like 'embeddings_*', 'outcomes', 'outcomes_mask', etc. args: Namespace with configuration Returns: X_3d: (batch_size, seq_len, input_dim) tensor y_3d: (batch_size, seq_len, num_outcomes) tensor mask_3d: (batch_size, seq_len, num_outcomes) boolean tensor \"\"\" Expected Shapes \u00b6 X_3d : (batch_size, seq_len, input_dim) - Input features y_3d : (batch_size, seq_len, num_outcomes) - Target outcomes mask_3d : (batch_size, seq_len, num_outcomes) - Boolean mask indicating valid samples Using Pre-built Models \u00b6 The easiest way to use sklearn models is to import the pre-built adapters: from src import RidgeForecastModel, AutoRegressiveRidge, SklearnModule, SklearnTrainer # Basic Ridge model model = RidgeForecastModel(alpha=1.0, random_state=42) # Autoregressive Ridge with 7-day history args.max_len = 7 model_ar = AutoRegressiveRidge(alpha=1.0, random_state=42) Custom Model Implementation \u00b6 You can also create your own adapter by implementing select_features() : from sklearn.linear_model import Ridge class CustomRidgeModel(Ridge): \"\"\"Custom adapter that selects specific embeddings.\"\"\" def select_features(self, batch_dict, args): # Your custom feature selection logic X_3d = batch_dict[\"embeddings_lang_z\"] y_3d = batch_dict[\"outcomes\"] mask_3d = batch_dict[\"outcomes_mask\"] return X_3d, y_3d, mask_3d Key Features \u00b6 PyTorch DataLoader Integration : Works seamlessly with PyTorch DataLoaders, aggregating batches automatically 3D to 2D Conversion : Handles reshaping between PyTorch's 3D tensor format and sklearn's 2D array format Exhaustive Metric Computation : Computes metrics for multiple OOTS/OOSS subsets, matching MILightningModule behavior Hyperparameter Search : Supports GridSearchCV and RandomizedSearchCV for hyperparameter tuning Model Persistence : Saves and loads models with structured paths ( output_dir/project_name/experiment_key/ ) Logging Integration : Works with Comet, TensorBoard, and other loggers for experiment tracking Adapter Pattern : Flexible feature selection via select_features() method Multi-Outcome Warning : Warns users about potential issues with multi-outcome models Example Usage \u00b6 Basic Training and Validation \u00b6 from src import ( SklearnModule, SklearnTrainer, RidgeForecastModel, AutoRegressiveRidge, get_default_args, get_logger, get_datasetDict, MIDataLoaderModule ) from datasets import load_from_disk # Setup args = get_default_args() data = load_from_disk(args.data_dir) datasetDict = get_datasetDict(train_data=data, val_folds=args.val_folds) for key in datasetDict: datasetDict[key] = datasetDict[key].with_format('torch') dataloaderModule = MIDataLoaderModule(args, datasetDict) logger = get_logger('comet', workspace=args.workspace, project_name=args.project_name, experiment_name=args.experiment_name, save_dir=args.output_dir) # Create model and module (using pre-built RidgeForecastModel) model = RidgeForecastModel(alpha=args.weight_decay, random_state=args.seed) module = SklearnModule(args, model) trainer = SklearnTrainer(output_dir=args.output_dir, logger=logger) # Train and validate results = trainer.fit( module, train_dataloader=dataloaderModule.train_dataloader(), val_dataloader=dataloaderModule.val_dataloader() ) print(f\"Training metrics: {results['train']}\") print(f\"Validation metrics: {results['val']}\") # Test if dataloaderModule.test_dataloader(): test_results = trainer.test(module, dataloaderModule.test_dataloader()) print(f\"Test metrics: {test_results}\") Autoregressive Model with History Windowing \u00b6 from src import AutoRegressiveRidge, SklearnModule, SklearnTrainer # Set history window size args.max_len = 7 # Use 7-day history # Create autoregressive model model = AutoRegressiveRidge(alpha=args.weight_decay, random_state=args.seed) module = SklearnModule(args, model) trainer = SklearnTrainer(output_dir=args.output_dir, logger=logger) # Works exactly like regular sklearn trainer! results = trainer.fit( module, train_dataloader=dataloaderModule.train_dataloader(), val_dataloader=dataloaderModule.val_dataloader() ) Hyperparameter Search \u00b6 # Define parameter grid param_grid = { 'alpha': [0.1, 1.0, 10.0, 100.0] } # Run grid search best_module = trainer.hyperparameter_search( module, param_grid, dataloaderModule.train_dataloader(), dataloaderModule.val_dataloader(), search_type='grid', cv=3 ) print(f\"Best validation metrics: {best_module.metrics['val']}\") Model Saving and Loading \u00b6 # Save model trainer.save_model(module, 'final_model.pkl') # Load model later loaded_module = trainer.load_model('final_model.pkl') See also: - examples/ptsd_stop_forecasting/test_sklearn_trainer.py for complete working examples with Ridge and Lasso models - src/mi_sklearn_model.py for all available sklearn model adapter classes","title":"Sklearn Trainer"},{"location":"sklearn_trainer/#sklearn-trainer-scikit-learn-integration","text":"","title":"Sklearn Trainer: Scikit-Learn Integration"},{"location":"sklearn_trainer/#overview","text":"SklearnModule and SklearnTrainer provide a PyTorch Lightning-like interface for scikit-learn models, allowing simple sklearn models (Ridge, Lasso, etc.) to work seamlessly with PyTorch DataLoaders. This is designed for models that have fit() and predict() methods and don't require gradient-based optimization. The sklearn trainer handles the conversion between PyTorch's 3D tensor format (batch_size, seq_len, features) and sklearn's 2D array format (n_samples, n_features), computes comprehensive evaluation metrics across multiple data subsets (OOTS/OOSS), and supports hyperparameter search via GridSearchCV and RandomizedSearchCV. Key Design Pattern : Sklearn models must implement a select_features() method (adapter pattern) that decides which embeddings to use from the batch dictionary, mirroring how PyTorch models choose their inputs. Module Organization : - sklearn_trainer.py : Contains SklearnModule and SklearnTrainer classes for training orchestration - mi_sklearn_model.py : Contains sklearn model adapter classes ( RidgeForecastModel , LassoForecastModel , AutoRegressiveRidge , AutoRegressiveLasso , etc.)","title":"Overview"},{"location":"sklearn_trainer/#helper-functions","text":"","title":"Helper Functions"},{"location":"sklearn_trainer/#collect_batch_dictdataloader","text":"What it does: Aggregates all batches from a PyTorch DataLoader into a single batch dictionary by concatenating tensors along the batch dimension. Inputs: - dataloader : PyTorch DataLoader yielding dictionary batches with keys like 'embeddings_*' , 'outcomes' , 'outcomes_mask' , 'oots_mask' , 'ooss_mask' , 'time_ids' , 'seq_id' , etc. Output: - Dict[str, torch.Tensor] : Dictionary with the same keys as individual batches, where values are concatenated tensors over all batches along dim=0.","title":"collect_batch_dict(dataloader)"},{"location":"sklearn_trainer/#reshape_for_sklearnx-y-mask","text":"What it does: Converts 3D PyTorch tensors to 2D numpy arrays suitable for sklearn models, filtering out invalid samples (where mask is False). Inputs: - X : (batch_size, seq_len, input_dim) tensor - y : (batch_size, seq_len, num_outcomes) tensor - mask : (batch_size, seq_len, num_outcomes) boolean tensor Output: - X_2d : (n_valid_samples, input_dim) numpy array - y_2d : (n_valid_samples, num_outcomes) numpy array - valid_indices : List of (batch_idx, time_idx) tuples for reconstruction Important Note on Multi-Outcome Models: This function uses mask.any(dim=-1) which includes timesteps where at least one outcome is valid. For multi-outcome models, this means: - If outcomes_mask = [1, 1, 0] , this sample is included in training - Sklearn will train on all outcomes, including the invalid one (with mask=0) - This is suboptimal for multi-outcome sklearn models as sklearn wastes effort predicting invalid outcomes For single-outcome models : This is not an issue since there's only one outcome. For multi-outcome models : Consider using separate sklearn models per outcome or modifying this function to use mask.all(dim=-1) to only include fully valid samples.","title":"reshape_for_sklearn(X, y, mask)"},{"location":"sklearn_trainer/#reconstruct_from_sklearnpredictions-original_shape-valid_indices-mask","text":"What it does: Reconstructs 3D predictions from sklearn's 2D output, placing predictions at valid positions and filling invalid positions with zeros. Inputs: - predictions : (n_valid_samples, num_outcomes) numpy array - original_shape : (batch_size, seq_len, num_outcomes) tuple - valid_indices : List of (batch_idx, time_idx) tuples - mask : Original mask tensor (batch_size, seq_len, num_outcomes) Output: - preds_3d : (batch_size, seq_len, num_outcomes) tensor","title":"reconstruct_from_sklearn(predictions, original_shape, valid_indices, mask)"},{"location":"sklearn_trainer/#method-reference","text":"","title":"Method Reference"},{"location":"sklearn_trainer/#sklearnmoduleargs-model","text":"What it does: Wraps a sklearn model to work with PyTorch DataLoaders, handling data reshaping, training, evaluation, and metric computation. Inputs: - args : Namespace or dict containing hyperparameters and configuration (must include metrics_reduction for metric computation). - model : Sklearn model instance with fit() and predict() methods. Must also implement select_features(batch_dict, args) that returns (X_3d, y_3d, mask_3d) tensors. Output: - An object with the following key methods: - fit(dataloader) : Train the sklearn model and compute training metrics - evaluate(dataloader, split='val') : Evaluate and compute exhaustive metrics for OOTS/OOSS subsets - predict(dataloader) : Make predictions without computing metrics (no labels needed) - compute_metrics(preds, targets, mask) : Compute basic metrics (MSE, SMAPE, Pearson, MAE) - compute_exhaustive_metrics(preds, targets, mask, oots_mask, ooss_mask) : Compute metrics for multiple subsets What it expects as input: - DataLoaders producing batch dictionaries with keys like 'embeddings_*' , 'outcomes' , 'outcomes_mask' , 'oots_mask' , 'ooss_mask' , etc. (see datamodule.md ) What the output looks like: - Stores predictions and metrics internally in self.predictions and self.metrics dictionaries - Returns metric dictionaries from fit() and evaluate() methods","title":"SklearnModule(args, model)"},{"location":"sklearn_trainer/#fitdataloader","text":"What it does: Trains the sklearn model on data from the dataloader, computes training metrics, and stores predictions. Inputs: - dataloader : PyTorch DataLoader Output: - Dictionary with training metrics: {'mse': ..., 'smape': ..., 'pearsonr': ..., 'mae': ...}","title":"fit(dataloader)"},{"location":"sklearn_trainer/#evaluatedataloader-splitval","text":"What it does: Evaluates the sklearn model and computes metrics for multiple data subsets based on oots_mask and ooss_mask : - ws_wt : within sample, within time (ooss==0 & oots==0) - valset : all validation data (oots==1 OR ooss==1) - ws_oots : within sample, out of time (ooss==0 & oots==1) - wt_ooss : within time, out of sample (ooss==1 & oots==0) - oots_ooss : out of time, out of sample (ooss==1 & oots==1) - oots : all out of time samples (oots==1) - ooss : all out of sample sequences (ooss==1) Inputs: - dataloader : PyTorch DataLoader - split : 'val' or 'test' (used for storing predictions/metrics) Output: - Dictionary with evaluation metrics for all subsets: {'ws_wt_mse': ..., 'valset_mse': ..., 'ws_oots_mse': ..., ...} . Empty subsets return -1.0 for all metrics.","title":"evaluate(dataloader, split='val')"},{"location":"sklearn_trainer/#predictdataloader","text":"What it does: Makes predictions without computing metrics (labels are optional). Inputs: - dataloader : PyTorch DataLoader (may not have labels) Output: - Dictionary with keys: 'preds' , 'outcomes' , 'outcomes_mask' , 'seq_id' , 'time_ids' , 'oots_mask' , 'ooss_mask'","title":"predict(dataloader)"},{"location":"sklearn_trainer/#compute_metricspreds-targets-mask","text":"What it does: Computes evaluation metrics using mi_eval functions (MSE, SMAPE, Pearson correlation, MAE) with the reduction mode specified in args.metrics_reduction . Inputs: - preds : (batch_size, seq_len, num_outcomes) tensor - targets : (batch_size, seq_len, num_outcomes) tensor - mask : (batch_size, seq_len, num_outcomes) tensor Output: - Dictionary with metric values: {'mse': ..., 'smape': ..., 'pearsonr': ..., 'mae': ...} See evaluation.md for details on reduction modes.","title":"compute_metrics(preds, targets, mask)"},{"location":"sklearn_trainer/#compute_exhaustive_metricspreds-targets-mask-oots_mask-ooss_mask","text":"What it does: Computes metrics for multiple data subsets based on oots_mask and ooss_mask , matching the behavior of MILightningModule.validation_step . Handles shape validation and correctly interprets time-wise oots_mask and sequence-wise ooss_mask . Inputs: - preds : (batch_size, seq_len, num_outcomes) tensor - targets : (batch_size, seq_len, num_outcomes) tensor - mask : (batch_size, seq_len, num_outcomes) tensor - oots_mask : (batch_size, seq_len) tensor - out of time indicator (time-wise) - ooss_mask : (batch_size,) or (batch_size, 1) tensor - out of sample indicator (sequence-wise) Output: - Dictionary with metrics for all subsets (same as evaluate() output)","title":"compute_exhaustive_metrics(preds, targets, mask, oots_mask, ooss_mask)"},{"location":"sklearn_trainer/#sklearntraineroutput_dir-loggernone-trainer_params","text":"What it does: Orchestrates training, validation, testing, and hyperparameter search for sklearn models, similar to PyTorch Lightning's Trainer. Inputs: - output_dir : Directory path for saving models and results - logger : Optional logger instance (Comet, TensorBoard, etc.) for experiment tracking - **trainer_params : Additional trainer configuration parameters Output: - An object with the following key methods: - fit(module, train_dataloader, val_dataloader=None) : Train and optionally validate - validate(module, val_dataloader) : Validate the model - test(module, test_dataloader) : Test the model - predict(module, predict_dataloader) : Make predictions - hyperparameter_search(...) : Perform GridSearchCV or RandomizedSearchCV - save_model(module, filename) : Save module to disk - load_model(filename) : Load saved module from disk","title":"SklearnTrainer(output_dir, logger=None, **trainer_params)"},{"location":"sklearn_trainer/#fitmodule-train_dataloader-val_dataloadernone","text":"What it does: Trains the sklearn model and optionally validates it, logging metrics and saving the model. Inputs: - module : SklearnModule instance - train_dataloader : Training data loader - val_dataloader : Optional validation data loader Output: - Dictionary with keys 'train' and 'val' , each containing metric dictionaries","title":"fit(module, train_dataloader, val_dataloader=None)"},{"location":"sklearn_trainer/#validatemodule-val_dataloader","text":"What it does: Validates the model (can be called anytime, not just after training). Inputs: - module : SklearnModule instance - val_dataloader : Validation data loader Output: - Dictionary with validation metrics (exhaustive subset metrics)","title":"validate(module, val_dataloader)"},{"location":"sklearn_trainer/#testmodule-test_dataloader","text":"What it does: Tests the model on the test set. Inputs: - module : SklearnModule instance - test_dataloader : Test data loader Output: - Dictionary with test metrics (exhaustive subset metrics)","title":"test(module, test_dataloader)"},{"location":"sklearn_trainer/#predictmodule-predict_dataloader","text":"What it does: Makes predictions without labels. Inputs: - module : SklearnModule instance - predict_dataloader : Data loader (may not have labels) Output: - Dictionary with predictions and metadata","title":"predict(module, predict_dataloader)"},{"location":"sklearn_trainer/#hyperparameter_searchmodule-param_grid-train_dataloader-val_dataloader-search_typegrid-n_iter10-cv3","text":"What it does: Performs hyperparameter search using GridSearchCV or RandomizedSearchCV , evaluates the best model on the validation set, and saves it. Inputs: - module : SklearnModule instance (will be cloned internally) - param_grid : Dictionary of parameter names to lists of values (e.g., {'alpha': [0.1, 1.0, 10.0]} ) - train_dataloader : Training data loader - val_dataloader : Validation data loader - search_type : 'grid' or 'random' - n_iter : Number of iterations for random search - cv : Number of cross-validation folds Output: - SklearnModule instance with the best model (from search.best_estimator_ )","title":"hyperparameter_search(module, param_grid, train_dataloader, val_dataloader, search_type='grid', n_iter=10, cv=3)"},{"location":"sklearn_trainer/#save_modelmodule-filename","text":"What it does: Saves the module (including the sklearn model, args, metrics, and predictions) to disk. Uses output_dir/project_name/experiment_key/ structure when logger is available, otherwise saves to output_dir/ . Inputs: - module : SklearnModule instance - filename : Name of the file to save (e.g., 'final_model.pkl' ) Output: - None (side effect: saves to disk)","title":"save_model(module, filename)"},{"location":"sklearn_trainer/#load_modelfilename","text":"What it does: Loads a saved module from disk, reconstructing the SklearnModule with the saved model, args, metrics, and predictions. Inputs: - filename : Name of the file to load Output: - SklearnModule instance","title":"load_model(filename)"},{"location":"sklearn_trainer/#available-sklearn-model-classes","text":"Pre-built sklearn model adapters are available in mi_sklearn_model.py :","title":"Available Sklearn Model Classes"},{"location":"sklearn_trainer/#basic-models-no-history-windowing","text":"RidgeForecastModel : Ridge regression adapter that selects embeddings from batch dictionary LassoForecastModel : Lasso regression adapter with the same feature selection logic","title":"Basic Models (No History Windowing)"},{"location":"sklearn_trainer/#autoregressive-models-with-history-windowing","text":"AutoRegressiveRidge : Ridge regression with sliding window history (uses args.max_len ) AutoRegressiveLasso : Lasso regression with sliding window history (uses args.max_len ) These models automatically handle history windowing when args.max_len > 1 , expanding each timestep's features to include the current and previous max_len - 1 timesteps.","title":"Autoregressive Models (With History Windowing)"},{"location":"sklearn_trainer/#adapter-pattern-select_features-interface","text":"Sklearn models used with SklearnModule must implement a select_features() method that defines how to extract input features, targets, and masks from the aggregated batch dictionary. This mirrors the PyTorch design where the model decides which embeddings_* keys to use.","title":"Adapter Pattern: select_features Interface"},{"location":"sklearn_trainer/#interface-signature","text":"def select_features(self, batch_dict: Dict[str, torch.Tensor], args) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: \"\"\" Args: batch_dict: Dictionary with keys like 'embeddings_*', 'outcomes', 'outcomes_mask', etc. args: Namespace with configuration Returns: X_3d: (batch_size, seq_len, input_dim) tensor y_3d: (batch_size, seq_len, num_outcomes) tensor mask_3d: (batch_size, seq_len, num_outcomes) boolean tensor \"\"\"","title":"Interface Signature"},{"location":"sklearn_trainer/#expected-shapes","text":"X_3d : (batch_size, seq_len, input_dim) - Input features y_3d : (batch_size, seq_len, num_outcomes) - Target outcomes mask_3d : (batch_size, seq_len, num_outcomes) - Boolean mask indicating valid samples","title":"Expected Shapes"},{"location":"sklearn_trainer/#using-pre-built-models","text":"The easiest way to use sklearn models is to import the pre-built adapters: from src import RidgeForecastModel, AutoRegressiveRidge, SklearnModule, SklearnTrainer # Basic Ridge model model = RidgeForecastModel(alpha=1.0, random_state=42) # Autoregressive Ridge with 7-day history args.max_len = 7 model_ar = AutoRegressiveRidge(alpha=1.0, random_state=42)","title":"Using Pre-built Models"},{"location":"sklearn_trainer/#custom-model-implementation","text":"You can also create your own adapter by implementing select_features() : from sklearn.linear_model import Ridge class CustomRidgeModel(Ridge): \"\"\"Custom adapter that selects specific embeddings.\"\"\" def select_features(self, batch_dict, args): # Your custom feature selection logic X_3d = batch_dict[\"embeddings_lang_z\"] y_3d = batch_dict[\"outcomes\"] mask_3d = batch_dict[\"outcomes_mask\"] return X_3d, y_3d, mask_3d","title":"Custom Model Implementation"},{"location":"sklearn_trainer/#key-features","text":"PyTorch DataLoader Integration : Works seamlessly with PyTorch DataLoaders, aggregating batches automatically 3D to 2D Conversion : Handles reshaping between PyTorch's 3D tensor format and sklearn's 2D array format Exhaustive Metric Computation : Computes metrics for multiple OOTS/OOSS subsets, matching MILightningModule behavior Hyperparameter Search : Supports GridSearchCV and RandomizedSearchCV for hyperparameter tuning Model Persistence : Saves and loads models with structured paths ( output_dir/project_name/experiment_key/ ) Logging Integration : Works with Comet, TensorBoard, and other loggers for experiment tracking Adapter Pattern : Flexible feature selection via select_features() method Multi-Outcome Warning : Warns users about potential issues with multi-outcome models","title":"Key Features"},{"location":"sklearn_trainer/#example-usage","text":"","title":"Example Usage"},{"location":"sklearn_trainer/#basic-training-and-validation","text":"from src import ( SklearnModule, SklearnTrainer, RidgeForecastModel, AutoRegressiveRidge, get_default_args, get_logger, get_datasetDict, MIDataLoaderModule ) from datasets import load_from_disk # Setup args = get_default_args() data = load_from_disk(args.data_dir) datasetDict = get_datasetDict(train_data=data, val_folds=args.val_folds) for key in datasetDict: datasetDict[key] = datasetDict[key].with_format('torch') dataloaderModule = MIDataLoaderModule(args, datasetDict) logger = get_logger('comet', workspace=args.workspace, project_name=args.project_name, experiment_name=args.experiment_name, save_dir=args.output_dir) # Create model and module (using pre-built RidgeForecastModel) model = RidgeForecastModel(alpha=args.weight_decay, random_state=args.seed) module = SklearnModule(args, model) trainer = SklearnTrainer(output_dir=args.output_dir, logger=logger) # Train and validate results = trainer.fit( module, train_dataloader=dataloaderModule.train_dataloader(), val_dataloader=dataloaderModule.val_dataloader() ) print(f\"Training metrics: {results['train']}\") print(f\"Validation metrics: {results['val']}\") # Test if dataloaderModule.test_dataloader(): test_results = trainer.test(module, dataloaderModule.test_dataloader()) print(f\"Test metrics: {test_results}\")","title":"Basic Training and Validation"},{"location":"sklearn_trainer/#autoregressive-model-with-history-windowing","text":"from src import AutoRegressiveRidge, SklearnModule, SklearnTrainer # Set history window size args.max_len = 7 # Use 7-day history # Create autoregressive model model = AutoRegressiveRidge(alpha=args.weight_decay, random_state=args.seed) module = SklearnModule(args, model) trainer = SklearnTrainer(output_dir=args.output_dir, logger=logger) # Works exactly like regular sklearn trainer! results = trainer.fit( module, train_dataloader=dataloaderModule.train_dataloader(), val_dataloader=dataloaderModule.val_dataloader() )","title":"Autoregressive Model with History Windowing"},{"location":"sklearn_trainer/#hyperparameter-search","text":"# Define parameter grid param_grid = { 'alpha': [0.1, 1.0, 10.0, 100.0] } # Run grid search best_module = trainer.hyperparameter_search( module, param_grid, dataloaderModule.train_dataloader(), dataloaderModule.val_dataloader(), search_type='grid', cv=3 ) print(f\"Best validation metrics: {best_module.metrics['val']}\")","title":"Hyperparameter Search"},{"location":"sklearn_trainer/#model-saving-and-loading","text":"# Save model trainer.save_model(module, 'final_model.pkl') # Load model later loaded_module = trainer.load_model('final_model.pkl') See also: - examples/ptsd_stop_forecasting/test_sklearn_trainer.py for complete working examples with Ridge and Lasso models - src/mi_sklearn_model.py for all available sklearn model adapter classes","title":"Model Saving and Loading"},{"location":"utils/","text":"Utilities \u00b6 See evaluation.md for evaluation metrics and logger.md for logging utilities.","title":"Utils"},{"location":"utils/#utilities","text":"See evaluation.md for evaluation metrics and logger.md for logging utilities.","title":"Utilities"}]}