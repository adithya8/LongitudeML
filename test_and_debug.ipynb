{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the dataset module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import get_datasetDict, create_mask, default_collate_fn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "BATCH_SEQ_LEN = 10\n",
    "FEAT_DIM = 8\n",
    "SEQ_LENS_TRAIN = torch.tensor([6, 3, 5, 10, 4, 2], dtype=torch.long)\n",
    "SEQ_LENS_VAL = torch.tensor([4, 2, 7, 8, 9, 3], dtype=torch.long)\n",
    "SEQ_LENS_TEST = torch.tensor([5, 3, 6, 9, 5, 7], dtype=torch.long)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "embeddings_train = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_train = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_TRAIN[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_train = [embeddings[:, :SEQ_LENS_TRAIN[i]] for i, embeddings in enumerate(embeddings_train)]\n",
    "train_data = {'embeddings': embeddings_train, 'labels': labels_train, 'seq_num': seq_lens}\n",
    "\n",
    "embeddings_val = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_val = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_VAL[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_val = [embeddings[:, :SEQ_LENS_VAL[i]] for i, embeddings in enumerate(embeddings_val)]\n",
    "val_data = {'embeddings': embeddings_val, 'labels': labels_val, 'seq_num': seq_lens}\n",
    "\n",
    "embeddings_test = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_test = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_TEST[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_test = [embeddings[:, :SEQ_LENS_TEST[i]] for i, embeddings in enumerate(embeddings_test)]\n",
    "test_data = {'embeddings': embeddings_test, 'labels': labels_test, 'seq_num': seq_lens}\n",
    "\n",
    "datasetDict = get_datasetDict(train_data=train_data, val_data=val_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 8])\n",
      "torch.Size([1, 3, 8])\n",
      "torch.Size([1, 5, 8])\n",
      "torch.Size([1, 10, 8])\n",
      "torch.Size([1, 4, 8])\n",
      "torch.Size([1, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "embeddings_train = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "for i, embeddings in enumerate(embeddings_train):\n",
    "    print (embeddings[:, :SEQ_LENS_TRAIN[i]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['embeddings', 'labels', 'seq_num'],\n",
       "    num_rows: 6\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetDict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 8]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(datasetDict['train'][5]['embeddings']).shape, torch.tensor(datasetDict['train'][5]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1c43358f534844bb267bd41342c257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783e9ff5187742ccb5b530699c6588a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029a69ec26a74c688d31392ea0e76b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetDict_mask = datasetDict.map(create_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetDict_mask['train'][0:4]['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(datasetDict_mask['train'], batch_size=3, shuffle=False, collate_fn=default_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users2/avirinchipur/NLP/emi/src/mi_datamodule.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[k] = torch.cat([torch.tensor(f[k]) for f in features], dim=0)\n"
     ]
    }
   ],
   "source": [
    "nxt = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetDict_mask['train'][0]['seq_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxt['embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxt['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxt['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5],\n",
       "        [0, 1, 2, 0, 0, 0],\n",
       "        [0, 1, 2, 3, 4, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxt['seq_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9006,  0.2286,  0.0249, -0.3460,  0.2868, -0.7308,  0.1748, -1.0939],\n",
       "        [-1.6022,  1.3529,  1.2888,  0.0523, -1.5469,  0.7567,  0.7755,  2.0265],\n",
       "        [ 0.0358,  0.1206, -0.8057, -0.2076, -0.9319, -1.5910, -1.1360, -0.5226],\n",
       "        [-0.5188, -1.5013, -1.9267,  0.1279,  1.0229, -0.5558,  0.7043,  0.7099],\n",
       "        [ 1.7744, -0.9216,  0.9624, -0.3370, -1.1753,  0.3581,  0.4788,  1.3537],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxt['embeddings'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9968e+11,  4.5695e-41,  3.5287e-19],\n",
       "        [ 3.0740e-41,  4.4842e-44,  0.0000e+00],\n",
       "        [ 1.5695e-43,  0.0000e+00,  3.4970e-19]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3,3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing MIDataLoaderModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src import get_default_args\n",
    "from src import get_datasetDict, create_mask, default_collate_fn, recurrent\n",
    "from src import MIDataLoaderModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "BATCH_SEQ_LEN = 10\n",
    "FEAT_DIM = 8\n",
    "SEQ_LENS_TRAIN = torch.tensor([6, 3, 5, 10, 4, 2], dtype=torch.long)\n",
    "SEQ_LENS_VAL = torch.tensor([4, 2, 7, 8, 9, 3], dtype=torch.long)\n",
    "SEQ_LENS_TEST = torch.tensor([5, 3, 6, 9, 5, 7], dtype=torch.long)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "embeddings_train = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_train = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_TRAIN[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_train = [embeddings[:, :SEQ_LENS_TRAIN[i]] for i, embeddings in enumerate(embeddings_train)]\n",
    "train_data = {'embeddings': embeddings_train, 'labels': labels_train, 'seq_num': seq_lens}\n",
    "\n",
    "embeddings_val = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_val = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_VAL[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_val = [embeddings[:, :SEQ_LENS_VAL[i]] for i, embeddings in enumerate(embeddings_val)]\n",
    "val_data = {'embeddings': embeddings_val, 'labels': labels_val, 'seq_num': seq_lens}\n",
    "\n",
    "embeddings_test = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_test = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_TEST[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_test = [embeddings[:, :SEQ_LENS_TEST[i]] for i, embeddings in enumerate(embeddings_test)]\n",
    "test_data = {'embeddings': embeddings_test, 'labels': labels_test, 'seq_num': seq_lens}\n",
    "\n",
    "datasetDict = get_datasetDict(train_data=train_data, val_data=val_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99a399041bd4c7ab60a32196c3fa9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdebe47428946d7aef7a2c86d5595e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042deb7aa4764a438b5452618ac95d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetDict_mask = datasetDict.map(create_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = MIDataLoaderModule(data_args=get_default_args(jupyter=True), datasets=datasetDict_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dataloader.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users2/avirinchipur/NLP/emi/src/mi_datamodule.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[k] = torch.cat([torch.tensor(f[k]) for f in features], dim=0)\n"
     ]
    }
   ],
   "source": [
    "a = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings': tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431,\n",
       "           -1.6047],\n",
       "          [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,\n",
       "            0.7624],\n",
       "          [ 1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,\n",
       "            1.6806],\n",
       "          [ 1.2791,  1.2964,  0.6105,  1.3347, -0.2316,  0.0418, -0.2516,\n",
       "            0.8599],\n",
       "          [-1.3847, -0.8712, -0.2234,  1.7174,  0.3189, -0.4245,  0.3057,\n",
       "           -0.7746],\n",
       "          [-1.5576,  0.9956, -0.8798, -0.6011, -1.2742,  2.1228, -1.2347,\n",
       "           -0.4879],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       " \n",
       "         [[ 0.0109, -0.3387, -1.3407, -0.5854,  0.5362,  0.5246,  1.1412,\n",
       "            0.0516],\n",
       "          [ 0.7440, -0.4816, -1.0495,  0.6039, -1.7223, -0.8278,  1.3347,\n",
       "            0.4835],\n",
       "          [-2.5095,  0.4880,  0.7846,  0.0286,  0.6408,  0.5832,  1.0669,\n",
       "           -0.4502],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       " \n",
       "         [[-1.9006,  0.2286,  0.0249, -0.3460,  0.2868, -0.7308,  0.1748,\n",
       "           -1.0939],\n",
       "          [-1.6022,  1.3529,  1.2888,  0.0523, -1.5469,  0.7567,  0.7755,\n",
       "            2.0265],\n",
       "          [ 0.0358,  0.1206, -0.8057, -0.2076, -0.9319, -1.5910, -1.1360,\n",
       "           -0.5226],\n",
       "          [-0.5188, -1.5013, -1.9267,  0.1279,  1.0229, -0.5558,  0.7043,\n",
       "            0.7099],\n",
       "          [ 1.7744, -0.9216,  0.9624, -0.3370, -1.1753,  0.3581,  0.4788,\n",
       "            1.3537],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       " \n",
       "         [[-0.9291,  0.2762, -0.5389,  0.4626, -0.8719, -0.0271, -0.3532,\n",
       "            1.4639],\n",
       "          [ 1.2554, -0.7150,  0.8539,  0.5130,  0.5397,  0.5655,  0.5058,\n",
       "            0.2225],\n",
       "          [-0.6855,  0.5636, -1.5072, -1.6107, -1.4790,  0.4323, -0.1250,\n",
       "            0.7821],\n",
       "          [-1.5988, -0.1091,  0.7152,  0.0391,  1.3059,  0.2466, -1.9776,\n",
       "            0.0179],\n",
       "          [-1.3793,  0.6258, -2.5850, -0.0240, -0.1222, -0.7470,  1.7093,\n",
       "            0.0579],\n",
       "          [ 1.1930,  1.9373,  0.7287,  0.9809,  0.4146,  1.1566,  0.2691,\n",
       "           -0.0366],\n",
       "          [ 0.9733, -1.0151, -0.5419, -0.4410, -0.3136, -0.1293, -0.7150,\n",
       "           -0.0476],\n",
       "          [ 2.0207,  0.2539,  0.9364,  0.7122, -0.0318,  0.1016,  1.3433,\n",
       "            0.7133],\n",
       "          [ 0.4038, -0.7140,  0.8337, -0.9585,  0.4536,  1.2461, -2.3065,\n",
       "           -1.2869],\n",
       "          [ 0.1799, -2.1268, -0.1341, -1.0408, -0.7647, -0.0553,  1.2049,\n",
       "           -0.9825]],\n",
       " \n",
       "         [[ 0.4334, -0.7172,  1.0554, -1.4534,  0.4652,  0.3714, -0.0047,\n",
       "            0.0795],\n",
       "          [ 0.3782,  0.7051, -1.7237, -0.8435,  0.4351,  0.2659, -0.5871,\n",
       "            0.0827],\n",
       "          [ 0.8854,  0.1824,  0.7864, -0.0579,  0.5667, -0.7098, -0.4875,\n",
       "            0.0501],\n",
       "          [ 0.6084,  1.6309, -0.0847,  1.0844,  0.9478, -0.6766, -0.5730,\n",
       "           -0.3303],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       " \n",
       "         [[ 0.0247, -1.0641, -0.7602, -0.4075,  0.9624, -0.1426,  0.1527,\n",
       "           -0.0388],\n",
       "          [ 0.9446, -1.5824,  0.9871,  1.1457, -0.1418, -0.2763, -0.1932,\n",
       "            0.7768],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]]]),\n",
       " 'labels': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " 'seq_num': tensor([[0, 1, 2, 3, 4, 5, 0, 0, 0, 0],\n",
       "         [0, 1, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 2, 3, 4, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "         [0, 1, 2, 3, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'mask': tensor([[ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False]])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src import get_datasetDict, create_mask, default_collate_fn, recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "BATCH_SEQ_LEN = 10\n",
    "FEAT_DIM = 8\n",
    "SEQ_LENS_TRAIN = torch.tensor([6, 3, 5, 10, 4, 2], dtype=torch.long)\n",
    "SEQ_LENS_VAL = torch.tensor([4, 2, 7, 8, 9, 3], dtype=torch.long)\n",
    "SEQ_LENS_TEST = torch.tensor([5, 3, 6, 9, 5, 7], dtype=torch.long)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "embeddings_train = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_train = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_TRAIN[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_train = [embeddings[:, :SEQ_LENS_TRAIN[i]] for i, embeddings in enumerate(embeddings_train)]\n",
    "train_data = {'embeddings': embeddings_train, 'labels': labels_train, 'seq_num': seq_lens}\n",
    "\n",
    "embeddings_val = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_val = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_VAL[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_val = [embeddings[:, :SEQ_LENS_VAL[i]] for i, embeddings in enumerate(embeddings_val)]\n",
    "val_data = {'embeddings': embeddings_val, 'labels': labels_val, 'seq_num': seq_lens}\n",
    "\n",
    "embeddings_test = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_test = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_TEST[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_test = [embeddings[:, :SEQ_LENS_TEST[i]] for i, embeddings in enumerate(embeddings_test)]\n",
    "test_data = {'embeddings': embeddings_test, 'labels': labels_test, 'seq_num': seq_lens}\n",
    "\n",
    "datasetDict = get_datasetDict(train_data=train_data, val_data=val_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72977968fb97444b93aaec7a42231be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa98d463d9e0453cb2ad74eb6feb05c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48dc9ed541c4f639b22f52419f3dbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetDict_mask = datasetDict.map(create_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(datasetDict_mask['train'], batch_size=3, shuffle=False, collate_fn=default_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = recurrent(input_size=8, hidden_size=4, bidirectional=False, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users2/avirinchipur/NLP/emi/src/mi_datamodule.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[k] = torch.cat([torch.tensor(f[k]) for f in features], dim=0)\n"
     ]
    }
   ],
   "source": [
    "input_data = next(iter(train_dataloader))\n",
    "input_rep, mask = input_data['embeddings'], input_data['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 6, 8]), torch.Size([3, 6]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_rep.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(embeddings=input_rep, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(embeddings=input_rep, mask=mask, predict_last_valid_hidden_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from src import (\n",
    "    get_default_args,\n",
    "    get_datasetDict, create_mask, MIDataLoaderModule,\n",
    "    MILightningModule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ip='127.0.0.1', stdin='9008', control='9006', hb='9005', shell='9007', transport='\"tcp\"', iopub='9009', f='/users2/avirinchipur/.local/share/jupyter/runtime/kernel-v2-6457bPEAU76Ye9a.json', data_dir=None, train_file=None, dev_file=None, test_file=None, model='gru', input_size=8, num_classes=2, hidden_size=128, num_layers=1, dropout=0.0, bidirectional=False, epochs=10, train_batch_size=32, eval_batch_size=64, cross_entropy_class_weight=None, log_interval=10, save_strategy='best', save_dir=None, lr=0.001, weight_decay=0.0, num_workers=4, seed=42, **{'Session.signature_scheme': '\"hmac-sha256\"', 'Session.key': 'b\"38786ab2-19df-4f95-8885-1b584cd50b4a\"'})\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# get_data_args(parser)\n",
    "# get_model_args(parser)\n",
    "# get_training_args(parser)\n",
    "# args = parser.parse_args()\n",
    "args = get_default_args(jupyter=True)\n",
    "print (args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "BATCH_SEQ_LEN = 10\n",
    "FEAT_DIM = 8\n",
    "SEQ_LENS_TRAIN = torch.tensor([6, 3, 5, 10, 4, 2], dtype=torch.long)\n",
    "SEQ_LENS_VAL = torch.tensor([4, 2, 7, 8, 9, 10], dtype=torch.long)\n",
    "SEQ_LENS_TEST = torch.tensor([5, 3, 6, 9, 5, 10], dtype=torch.long)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "embeddings_train = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_train = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_TRAIN[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_train = [embeddings[:, :SEQ_LENS_TRAIN[i]] for i, embeddings in enumerate(embeddings_train)]\n",
    "train_data = {'embeddings': embeddings_train, 'labels': labels_train, 'seq_num': seq_lens}\n",
    "\n",
    "embeddings_val = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_val = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_VAL[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_val = [embeddings[:, :SEQ_LENS_VAL[i]] for i, embeddings in enumerate(embeddings_val)]\n",
    "val_data = {'embeddings': embeddings_val, 'labels': labels_val, 'seq_num': seq_lens}\n",
    "\n",
    "embeddings_test = torch.randn(BATCH_SIZE, 1, BATCH_SEQ_LEN, FEAT_DIM)\n",
    "labels_test = torch.randint(0, 2, (BATCH_SIZE, ), dtype=torch.long).unsqueeze(-1).expand(BATCH_SIZE, BATCH_SEQ_LEN)\n",
    "seq_lens = [list(range(SEQ_LENS_TEST[i])) for i in range(BATCH_SIZE)]\n",
    "embeddings_test = [embeddings[:, :SEQ_LENS_TEST[i]] for i, embeddings in enumerate(embeddings_test)]\n",
    "test_data = {'embeddings': embeddings_test, 'labels': labels_test, 'seq_num': seq_lens}\n",
    "\n",
    "datasetDict = get_datasetDict(train_data=train_data, val_data=val_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce584b63735248e78ce4cb7475facad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6b6ff707904e9fa3bf02766af39f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2aa57cfcfd14656b089f39d4624ddd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetDict = datasetDict.map(create_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = MIDataLoaderModule(args, datasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/data/avirinchipur/conda_envs/emi/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.max_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_module = MILightningModule(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MILightningModule(\n",
       "  (model): recurrent(\n",
       "    (model): ModuleList(\n",
       "      (0): GRU(8, 128, batch_first=True)\n",
       "      (1): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightning_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | recurrent         | 53.1 K\n",
      "1 | loss  | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------\n",
      "53.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.1 K    Total params\n",
      "0.212     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dbac99bb58480c86aba665db92f5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/avirinchipur/conda_envs/emi/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/users2/avirinchipur/NLP/emi/src/mi_datamodule.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[k] = torch.cat([torch.tensor(f[k]) for f in features], dim=0)\n",
      "/data/avirinchipur/conda_envs/emi/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/data/avirinchipur/conda_envs/emi/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86beffff564846f1a9a0b81e6a79789c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811a6d1fcd8e45d08864e7b3c7f8c170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf78ea0ff354cd4bb6a64f6d76a2e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5498084536894be6a701ca99343e5b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299f14ed9021420a8ebd5007998bc3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0f3b8038224ad68948fb74904d168b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a1c69dde4740b3a032d08c67a6992c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5274ed31ec439daed2b31f1375c952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89154a22248a4755ae7cc6f13aeb2d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd508d69e76544b4acd6518d410818ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e97aaa81434fccb5f4960af7c34b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(lightning_module, datamodule=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [0.6943069696426392,\n",
       "  0.6897984147071838,\n",
       "  0.6854313015937805,\n",
       "  0.6811696887016296,\n",
       "  0.6769759058952332,\n",
       "  0.6728121042251587,\n",
       "  0.6686407923698425,\n",
       "  0.6644251942634583,\n",
       "  0.6601274609565735,\n",
       "  0.6557108163833618],\n",
       " 'val': [0.6947422623634338,\n",
       "  0.6961889863014221,\n",
       "  0.6977480053901672,\n",
       "  0.6994255185127258,\n",
       "  0.7012319564819336,\n",
       "  0.7031817436218262,\n",
       "  0.7052913904190063,\n",
       "  0.7075844407081604,\n",
       "  0.7100932002067566,\n",
       "  0.7128605246543884,\n",
       "  0.7159401178359985],\n",
       " 'test': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightning_module.epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl = dataloader.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users2/avirinchipur/NLP/emi/src/mi_datamodule.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[k] = torch.cat([torch.tensor(f[k]) for f in features], dim=0)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(tr_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(batch['mask'], torch.BoolTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings torch.Size([6, 9, 8])\n",
      "labels torch.Size([6, 10])\n",
      "seq_num torch.Size([6, 9])\n",
      "mask torch.Size([6, 9])\n"
     ]
    }
   ],
   "source": [
    "for k, v in batch.items():\n",
    "    print (k, v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
